{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(989, 8)\n",
      "  search_word                                        description  \\\n",
      "0     Siemens  15 Things You Didn't Know About SIEMENS | SUBS...   \n",
      "1     Siemens  From digitalisation to automation, weƒ??re cha...   \n",
      "2     Siemens  Are you interested in what Siemens does and wh...   \n",
      "3     Siemens  The most powerful HVDC transformer in the worl...   \n",
      "4     Siemens  Articolul complet pe site: https://cavaleria.r...   \n",
      "\n",
      "                               localized.description  \\\n",
      "0  15 Things You Didn't Know About SIEMENS | SUBS...   \n",
      "1  From digitalisation to automation, weƒ??re cha...   \n",
      "2  Are you interested in what Siemens does and wh...   \n",
      "3  The most powerful HVDC transformer in the worl...   \n",
      "4  Articolul complet pe site: https://cavaleria.r...   \n",
      "\n",
      "                                     localized.title  \\\n",
      "0            15 Things You Didn't Know About SIEMENS   \n",
      "1                What is it like to work at Siemens?   \n",
      "2                  Siemens - More than just business   \n",
      "3  Siemens presents: The first 1,100 kV HVDC Tran...   \n",
      "4  Ce ??nseamnŽŸ sŽŸ lucrezi la Siemens - Cavaler...   \n",
      "\n",
      "                                                tags  \\\n",
      "0  ['Alux', 'Alux.com', 'Alux Youtube', 'luxury l...   \n",
      "1  ['Siemens', 'Siemens UK', 'careers', 'jobs', '...   \n",
      "2  ['SIEMENS', 'products', 'Energy', 'Healthcare'...   \n",
      "3  ['Siemens', 'HVDC', 'Transformer', '1100kV', '...   \n",
      "4  ['Cavaleria.ro', 'hacking', 'siemens', 'job', ...   \n",
      "\n",
      "                                               title                Age  \\\n",
      "0            15 Things You Didn't Know About SIEMENS  323 days 12:06:13   \n",
      "1                What is it like to work at Siemens?  372 days 04:41:10   \n",
      "2                  Siemens - More than just business 1917 days 12:52:59   \n",
      "3  Siemens presents: The first 1,100 kV HVDC Tran...   42 days 11:22:18   \n",
      "4  Ce ??nseamnŽŸ sŽŸ lucrezi la Siemens - Cavaler...    0 days 03:48:01   \n",
      "\n",
      "   view_bucket  \n",
      "0          2.0  \n",
      "1          1.0  \n",
      "2          5.0  \n",
      "3          4.0  \n",
      "4          1.0  \n"
     ]
    }
   ],
   "source": [
    "%store -r word_df\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# pickle.dump(word_df, fileObject)\n",
    "# b = pickle.load(fileObject)\n",
    "\n",
    "print(word_df.shape)\n",
    "print(word_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "974\n"
     ]
    }
   ],
   "source": [
    "#Check to see if these two columns are the same\n",
    "print(word_df['localized.title'].equals(word_df['title']))\n",
    "print(word_df['localized.description'].equals(word_df['description']))\n",
    "print(np.count_nonzero(word_df['localized.description']==(word_df['description'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almost all descriptions are the same, so go ahead and drop one of the columns\n",
    "word_df = word_df.drop(columns=['localized.title'])\n",
    "word_df = word_df.drop(columns=['localized.description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = word_df[['description','tags','title']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Age</th>\n",
       "      <th colspan=\"8\" halign=\"left\">view_bucket</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Siemens</th>\n",
       "      <td>50</td>\n",
       "      <td>852 days 06:55:17.680000</td>\n",
       "      <td>730 days 21:00:42.421331</td>\n",
       "      <td>-5 days +13:24:35</td>\n",
       "      <td>348 days 03:57:33.750000</td>\n",
       "      <td>695 days 14:12:52</td>\n",
       "      <td>1228 days 18:59:02.500000</td>\n",
       "      <td>2785 days 15:34:21</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>4.601863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cats</th>\n",
       "      <td>50</td>\n",
       "      <td>297 days 19:52:12.560000</td>\n",
       "      <td>404 days 05:12:19.424387</td>\n",
       "      <td>-5 days +20:59:56</td>\n",
       "      <td>-2 days +14:59:59.250000</td>\n",
       "      <td>117 days 23:56:12</td>\n",
       "      <td>528 days 12:16:19.500000</td>\n",
       "      <td>1844 days 01:48:23</td>\n",
       "      <td>50.0</td>\n",
       "      <td>355.780000</td>\n",
       "      <td>594.014474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>384.25</td>\n",
       "      <td>2340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>christmas</th>\n",
       "      <td>50</td>\n",
       "      <td>170 days 16:36:44.660000</td>\n",
       "      <td>398 days 07:02:03.936969</td>\n",
       "      <td>-5 days +05:34:49</td>\n",
       "      <td>-4 days +09:44:55.250000</td>\n",
       "      <td>-1 days +11:42:59.500000</td>\n",
       "      <td>15 days 16:40:30.750000</td>\n",
       "      <td>1800 days 04:15:40</td>\n",
       "      <td>50.0</td>\n",
       "      <td>96.540000</td>\n",
       "      <td>232.797907</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>8.5</td>\n",
       "      <td>55.50</td>\n",
       "      <td>1172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donald trump</th>\n",
       "      <td>50</td>\n",
       "      <td>150 days 16:17:27.120000</td>\n",
       "      <td>465 days 10:30:16.153302</td>\n",
       "      <td>-5 days +07:16:01</td>\n",
       "      <td>-3 days +08:25:06.250000</td>\n",
       "      <td>-3 days +22:35:56</td>\n",
       "      <td>5 days 23:28:46.750000</td>\n",
       "      <td>2825 days 17:56:37</td>\n",
       "      <td>50.0</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>456.594593</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>3168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dude perfect</th>\n",
       "      <td>50</td>\n",
       "      <td>540 days 05:44:52.780000</td>\n",
       "      <td>613 days 17:54:27.446347</td>\n",
       "      <td>-4 days +04:02:11</td>\n",
       "      <td>138 days 07:58:30.750000</td>\n",
       "      <td>378 days 13:01:53</td>\n",
       "      <td>709 days 19:03:00.500000</td>\n",
       "      <td>3519 days 18:17:12</td>\n",
       "      <td>50.0</td>\n",
       "      <td>944.080000</td>\n",
       "      <td>783.887404</td>\n",
       "      <td>2.0</td>\n",
       "      <td>422.25</td>\n",
       "      <td>595.5</td>\n",
       "      <td>1263.50</td>\n",
       "      <td>3511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaming</th>\n",
       "      <td>50</td>\n",
       "      <td>65 days 09:37:05.520000</td>\n",
       "      <td>120 days 01:32:45.317851</td>\n",
       "      <td>-5 days +03:58:20</td>\n",
       "      <td>-4 days +15:46:20.500000</td>\n",
       "      <td>1 days 22:28:51.500000</td>\n",
       "      <td>83 days 22:45:08.500000</td>\n",
       "      <td>550 days 03:44:08</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>41.759760</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.00</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>golf</th>\n",
       "      <td>50</td>\n",
       "      <td>58 days 23:48:37.260000</td>\n",
       "      <td>273 days 06:45:47.156569</td>\n",
       "      <td>-5 days +01:21:17</td>\n",
       "      <td>-4 days +01:03:38.750000</td>\n",
       "      <td>-3 days +20:29:57.500000</td>\n",
       "      <td>9 days 17:29:44</td>\n",
       "      <td>1912 days 11:02:30</td>\n",
       "      <td>50.0</td>\n",
       "      <td>22.780000</td>\n",
       "      <td>133.319976</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horror</th>\n",
       "      <td>50</td>\n",
       "      <td>95 days 21:06:36.720000</td>\n",
       "      <td>172 days 09:52:51.241557</td>\n",
       "      <td>-9 days +08:59:59</td>\n",
       "      <td>-4 days +06:40:32.500000</td>\n",
       "      <td>5 days 15:44:06</td>\n",
       "      <td>118 days 16:43:51.500000</td>\n",
       "      <td>815 days 08:29:59</td>\n",
       "      <td>50.0</td>\n",
       "      <td>28.680000</td>\n",
       "      <td>57.749084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>18.50</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iphone</th>\n",
       "      <td>50</td>\n",
       "      <td>44 days 12:54:04.780000</td>\n",
       "      <td>123 days 16:00:21.882220</td>\n",
       "      <td>-5 days +06:00:00</td>\n",
       "      <td>-3 days +15:42:42.250000</td>\n",
       "      <td>1 days 13:29:58.500000</td>\n",
       "      <td>28 days 18:30:53.250000</td>\n",
       "      <td>614 days 21:07:58</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>73.207898</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>31.00</td>\n",
       "      <td>460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laugh</th>\n",
       "      <td>50</td>\n",
       "      <td>37 days 18:53:58.940000</td>\n",
       "      <td>112 days 11:12:24.320534</td>\n",
       "      <td>-5 days +05:29:57</td>\n",
       "      <td>-4 days +02:47:17.500000</td>\n",
       "      <td>-3 days +02:37:38.500000</td>\n",
       "      <td>10 days 17:36:17.250000</td>\n",
       "      <td>631 days 06:55:47</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.560000</td>\n",
       "      <td>55.466541</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>15.50</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mac</th>\n",
       "      <td>50</td>\n",
       "      <td>198 days 06:01:58.100000</td>\n",
       "      <td>568 days 07:14:23.539944</td>\n",
       "      <td>-5 days +04:41:37</td>\n",
       "      <td>-4 days +19:31:45.500000</td>\n",
       "      <td>-2 days +08:37:28</td>\n",
       "      <td>99 days 11:51:51</td>\n",
       "      <td>2685 days 17:28:33</td>\n",
       "      <td>50.0</td>\n",
       "      <td>99.540000</td>\n",
       "      <td>333.652894</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.50</td>\n",
       "      <td>1774.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mars</th>\n",
       "      <td>50</td>\n",
       "      <td>74 days 12:16:52.900000</td>\n",
       "      <td>170 days 09:47:04.148964</td>\n",
       "      <td>-5 days +09:37:33</td>\n",
       "      <td>-1 days +13:08:04.500000</td>\n",
       "      <td>1 days 12:58:21.500000</td>\n",
       "      <td>33 days 05:15:38.250000</td>\n",
       "      <td>736 days 09:32:46</td>\n",
       "      <td>50.0</td>\n",
       "      <td>13.460000</td>\n",
       "      <td>28.978676</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.75</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minecraft</th>\n",
       "      <td>50</td>\n",
       "      <td>3 days 09:31:07.520000</td>\n",
       "      <td>14 days 20:39:25.026309</td>\n",
       "      <td>-5 days +04:08:37</td>\n",
       "      <td>-4 days +04:37:11.500000</td>\n",
       "      <td>-3 days +01:55:51.500000</td>\n",
       "      <td>1 days 15:07:06</td>\n",
       "      <td>62 days 04:59:59</td>\n",
       "      <td>50.0</td>\n",
       "      <td>18.920000</td>\n",
       "      <td>28.982641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.5</td>\n",
       "      <td>20.50</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>50</td>\n",
       "      <td>284 days 14:32:39.680000</td>\n",
       "      <td>315 days 15:31:48.774248</td>\n",
       "      <td>-8 days +06:47:59</td>\n",
       "      <td>48 days 02:04:22.750000</td>\n",
       "      <td>187 days 20:39:38.500000</td>\n",
       "      <td>399 days 01:40:50.500000</td>\n",
       "      <td>1477 days 14:45:36</td>\n",
       "      <td>50.0</td>\n",
       "      <td>153.980000</td>\n",
       "      <td>216.524824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.25</td>\n",
       "      <td>88.0</td>\n",
       "      <td>179.00</td>\n",
       "      <td>1142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>music</th>\n",
       "      <td>40</td>\n",
       "      <td>512 days 00:07:11.375000</td>\n",
       "      <td>688 days 17:48:08.273441</td>\n",
       "      <td>-5 days +17:13:47</td>\n",
       "      <td>-1 days +12:07:57.500000</td>\n",
       "      <td>184 days 16:41:03.500000</td>\n",
       "      <td>803 days 18:04:12.250000</td>\n",
       "      <td>2850 days 05:04:39</td>\n",
       "      <td>40.0</td>\n",
       "      <td>894.200000</td>\n",
       "      <td>1460.454043</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.50</td>\n",
       "      <td>448.5</td>\n",
       "      <td>1019.75</td>\n",
       "      <td>7786.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>50</td>\n",
       "      <td>386 days 17:32:20.200000</td>\n",
       "      <td>687 days 12:23:44.668592</td>\n",
       "      <td>-10 days +21:21:28</td>\n",
       "      <td>-2 days +23:54:12</td>\n",
       "      <td>128 days 23:08:30</td>\n",
       "      <td>472 days 09:15:22.500000</td>\n",
       "      <td>3411 days 10:39:45</td>\n",
       "      <td>50.0</td>\n",
       "      <td>115.860000</td>\n",
       "      <td>424.801275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>36.00</td>\n",
       "      <td>2191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speedrun</th>\n",
       "      <td>50</td>\n",
       "      <td>111 days 17:04:11.100000</td>\n",
       "      <td>190 days 21:28:01.656107</td>\n",
       "      <td>-5 days +02:24:16</td>\n",
       "      <td>-4 days +10:48:29.500000</td>\n",
       "      <td>14 days 23:30:39.500000</td>\n",
       "      <td>161 days 06:44:54.500000</td>\n",
       "      <td>936 days 11:16:49</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.940000</td>\n",
       "      <td>17.537610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.50</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sports</th>\n",
       "      <td>49</td>\n",
       "      <td>39 days 02:40:43.102040</td>\n",
       "      <td>105 days 13:02:30.999832</td>\n",
       "      <td>-5 days +02:51:11</td>\n",
       "      <td>-5 days +12:54:56</td>\n",
       "      <td>-4 days +18:20:10</td>\n",
       "      <td>5 days 12:00:00</td>\n",
       "      <td>544 days 03:39:31</td>\n",
       "      <td>49.0</td>\n",
       "      <td>33.285714</td>\n",
       "      <td>100.453140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vacation</th>\n",
       "      <td>50</td>\n",
       "      <td>636 days 18:22:57.960000</td>\n",
       "      <td>914 days 15:30:01.796265</td>\n",
       "      <td>-10 days +22:55:53</td>\n",
       "      <td>-8 days +21:44:33.250000</td>\n",
       "      <td>186 days 03:43:06</td>\n",
       "      <td>1124 days 15:41:42.750000</td>\n",
       "      <td>3742 days 16:11:59</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.340000</td>\n",
       "      <td>158.210608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72.25</td>\n",
       "      <td>803.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video blogging</th>\n",
       "      <td>50</td>\n",
       "      <td>1128 days 12:53:28.899999</td>\n",
       "      <td>984 days 08:39:47.124790</td>\n",
       "      <td>5 days 11:43:20</td>\n",
       "      <td>356 days 02:56:11</td>\n",
       "      <td>786 days 04:30:09.500000</td>\n",
       "      <td>1561 days 01:48:14</td>\n",
       "      <td>3967 days 12:42:16</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10.060000</td>\n",
       "      <td>21.260685</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Age                                                       \\\n",
       "               count                       mean                       std   \n",
       "search_word                                                                 \n",
       "Siemens           50   852 days 06:55:17.680000  730 days 21:00:42.421331   \n",
       "cats              50   297 days 19:52:12.560000  404 days 05:12:19.424387   \n",
       "christmas         50   170 days 16:36:44.660000  398 days 07:02:03.936969   \n",
       "donald trump      50   150 days 16:17:27.120000  465 days 10:30:16.153302   \n",
       "dude perfect      50   540 days 05:44:52.780000  613 days 17:54:27.446347   \n",
       "gaming            50    65 days 09:37:05.520000  120 days 01:32:45.317851   \n",
       "golf              50    58 days 23:48:37.260000  273 days 06:45:47.156569   \n",
       "horror            50    95 days 21:06:36.720000  172 days 09:52:51.241557   \n",
       "iphone            50    44 days 12:54:04.780000  123 days 16:00:21.882220   \n",
       "laugh             50    37 days 18:53:58.940000  112 days 11:12:24.320534   \n",
       "mac               50   198 days 06:01:58.100000  568 days 07:14:23.539944   \n",
       "mars              50    74 days 12:16:52.900000  170 days 09:47:04.148964   \n",
       "minecraft         50     3 days 09:31:07.520000   14 days 20:39:25.026309   \n",
       "movies            50   284 days 14:32:39.680000  315 days 15:31:48.774248   \n",
       "music             40   512 days 00:07:11.375000  688 days 17:48:08.273441   \n",
       "python            50   386 days 17:32:20.200000  687 days 12:23:44.668592   \n",
       "speedrun          50   111 days 17:04:11.100000  190 days 21:28:01.656107   \n",
       "sports            49    39 days 02:40:43.102040  105 days 13:02:30.999832   \n",
       "vacation          50   636 days 18:22:57.960000  914 days 15:30:01.796265   \n",
       "video blogging    50  1128 days 12:53:28.899999  984 days 08:39:47.124790   \n",
       "\n",
       "                                                              \\\n",
       "                               min                       25%   \n",
       "search_word                                                    \n",
       "Siemens          -5 days +13:24:35  348 days 03:57:33.750000   \n",
       "cats             -5 days +20:59:56  -2 days +14:59:59.250000   \n",
       "christmas        -5 days +05:34:49  -4 days +09:44:55.250000   \n",
       "donald trump     -5 days +07:16:01  -3 days +08:25:06.250000   \n",
       "dude perfect     -4 days +04:02:11  138 days 07:58:30.750000   \n",
       "gaming           -5 days +03:58:20  -4 days +15:46:20.500000   \n",
       "golf             -5 days +01:21:17  -4 days +01:03:38.750000   \n",
       "horror           -9 days +08:59:59  -4 days +06:40:32.500000   \n",
       "iphone           -5 days +06:00:00  -3 days +15:42:42.250000   \n",
       "laugh            -5 days +05:29:57  -4 days +02:47:17.500000   \n",
       "mac              -5 days +04:41:37  -4 days +19:31:45.500000   \n",
       "mars             -5 days +09:37:33  -1 days +13:08:04.500000   \n",
       "minecraft        -5 days +04:08:37  -4 days +04:37:11.500000   \n",
       "movies           -8 days +06:47:59   48 days 02:04:22.750000   \n",
       "music            -5 days +17:13:47  -1 days +12:07:57.500000   \n",
       "python          -10 days +21:21:28         -2 days +23:54:12   \n",
       "speedrun         -5 days +02:24:16  -4 days +10:48:29.500000   \n",
       "sports           -5 days +02:51:11         -5 days +12:54:56   \n",
       "vacation        -10 days +22:55:53  -8 days +21:44:33.250000   \n",
       "video blogging     5 days 11:43:20         356 days 02:56:11   \n",
       "\n",
       "                                                                     \\\n",
       "                                     50%                        75%   \n",
       "search_word                                                           \n",
       "Siemens                695 days 14:12:52  1228 days 18:59:02.500000   \n",
       "cats                   117 days 23:56:12   528 days 12:16:19.500000   \n",
       "christmas       -1 days +11:42:59.500000    15 days 16:40:30.750000   \n",
       "donald trump           -3 days +22:35:56     5 days 23:28:46.750000   \n",
       "dude perfect           378 days 13:01:53   709 days 19:03:00.500000   \n",
       "gaming            1 days 22:28:51.500000    83 days 22:45:08.500000   \n",
       "golf            -3 days +20:29:57.500000            9 days 17:29:44   \n",
       "horror                   5 days 15:44:06   118 days 16:43:51.500000   \n",
       "iphone            1 days 13:29:58.500000    28 days 18:30:53.250000   \n",
       "laugh           -3 days +02:37:38.500000    10 days 17:36:17.250000   \n",
       "mac                    -2 days +08:37:28           99 days 11:51:51   \n",
       "mars              1 days 12:58:21.500000    33 days 05:15:38.250000   \n",
       "minecraft       -3 days +01:55:51.500000            1 days 15:07:06   \n",
       "movies          187 days 20:39:38.500000   399 days 01:40:50.500000   \n",
       "music           184 days 16:41:03.500000   803 days 18:04:12.250000   \n",
       "python                 128 days 23:08:30   472 days 09:15:22.500000   \n",
       "speedrun         14 days 23:30:39.500000   161 days 06:44:54.500000   \n",
       "sports                 -4 days +18:20:10            5 days 12:00:00   \n",
       "vacation               186 days 03:43:06  1124 days 15:41:42.750000   \n",
       "video blogging  786 days 04:30:09.500000         1561 days 01:48:14   \n",
       "\n",
       "                                   view_bucket                                \\\n",
       "                               max       count        mean          std  min   \n",
       "search_word                                                                    \n",
       "Siemens         2785 days 15:34:21        50.0    3.080000     4.601863  1.0   \n",
       "cats            1844 days 01:48:23        50.0  355.780000   594.014474  1.0   \n",
       "christmas       1800 days 04:15:40        50.0   96.540000   232.797907  1.0   \n",
       "donald trump    2825 days 17:56:37        50.0   92.500000   456.594593  1.0   \n",
       "dude perfect    3519 days 18:17:12        50.0  944.080000   783.887404  2.0   \n",
       "gaming           550 days 03:44:08        50.0   27.800000    41.759760  1.0   \n",
       "golf            1912 days 11:02:30        50.0   22.780000   133.319976  1.0   \n",
       "horror           815 days 08:29:59        50.0   28.680000    57.749084  1.0   \n",
       "iphone           614 days 21:07:58        50.0   32.540000    73.207898  1.0   \n",
       "laugh            631 days 06:55:47        50.0   27.560000    55.466541  1.0   \n",
       "mac             2685 days 17:28:33        50.0   99.540000   333.652894  1.0   \n",
       "mars             736 days 09:32:46        50.0   13.460000    28.978676  1.0   \n",
       "minecraft         62 days 04:59:59        50.0   18.920000    28.982641  1.0   \n",
       "movies          1477 days 14:45:36        50.0  153.980000   216.524824  1.0   \n",
       "music           2850 days 05:04:39        40.0  894.200000  1460.454043  2.0   \n",
       "python          3411 days 10:39:45        50.0  115.860000   424.801275  1.0   \n",
       "speedrun         936 days 11:16:49        50.0    9.940000    17.537610  1.0   \n",
       "sports           544 days 03:39:31        49.0   33.285714   100.453140  1.0   \n",
       "vacation        3742 days 16:11:59        50.0   85.340000   158.210608  1.0   \n",
       "video blogging  3967 days 12:42:16        50.0   10.060000    21.260685  1.0   \n",
       "\n",
       "                                                \n",
       "                   25%    50%      75%     max  \n",
       "search_word                                     \n",
       "Siemens           1.00    1.0     3.00    25.0  \n",
       "cats              3.00   55.0   384.25  2340.0  \n",
       "christmas         1.25    8.5    55.50  1172.0  \n",
       "donald trump      1.00    3.0     8.50  3168.0  \n",
       "dude perfect    422.25  595.5  1263.50  3511.0  \n",
       "gaming            3.00    6.0    41.00   196.0  \n",
       "golf              1.00    1.0     2.00   945.0  \n",
       "horror            1.00    4.5    18.50   224.0  \n",
       "iphone            1.00    3.5    31.00   460.0  \n",
       "laugh             1.00    3.5    15.50   230.0  \n",
       "mac               1.00    1.0    11.50  1774.0  \n",
       "mars              2.00    4.0    11.75   188.0  \n",
       "minecraft         2.25    4.5    20.50   109.0  \n",
       "movies           22.25   88.0   179.00  1142.0  \n",
       "music            41.50  448.5  1019.75  7786.0  \n",
       "python            1.00    5.0    36.00  2191.0  \n",
       "speedrun          1.00    1.0    11.50    85.0  \n",
       "sports            1.00    4.0    17.00   608.0  \n",
       "vacation          3.25   16.0    72.25   803.0  \n",
       "video blogging    1.00    1.0     8.50   121.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.groupby('search_word').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_word</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>Age</th>\n",
       "      <th>view_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Siemens</td>\n",
       "      <td>15 Things You Didn't Know About SIEMENS | SUBS...</td>\n",
       "      <td>['Alux', 'Alux.com', 'Alux Youtube', 'luxury l...</td>\n",
       "      <td>15 Things You Didn't Know About SIEMENS</td>\n",
       "      <td>323 days 12:06:13</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Siemens</td>\n",
       "      <td>From digitalisation to automation, weƒ??re cha...</td>\n",
       "      <td>['Siemens', 'Siemens UK', 'careers', 'jobs', '...</td>\n",
       "      <td>What is it like to work at Siemens?</td>\n",
       "      <td>372 days 04:41:10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siemens</td>\n",
       "      <td>Are you interested in what Siemens does and wh...</td>\n",
       "      <td>['SIEMENS', 'products', 'Energy', 'Healthcare'...</td>\n",
       "      <td>Siemens - More than just business</td>\n",
       "      <td>1917 days 12:52:59</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Siemens</td>\n",
       "      <td>The most powerful HVDC transformer in the worl...</td>\n",
       "      <td>['Siemens', 'HVDC', 'Transformer', '1100kV', '...</td>\n",
       "      <td>Siemens presents: The first 1,100 kV HVDC Tran...</td>\n",
       "      <td>42 days 11:22:18</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Siemens</td>\n",
       "      <td>Articolul complet pe site: https://cavaleria.r...</td>\n",
       "      <td>['Cavaleria.ro', 'hacking', 'siemens', 'job', ...</td>\n",
       "      <td>Ce ??nseamnŽŸ sŽŸ lucrezi la Siemens - Cavaler...</td>\n",
       "      <td>0 days 03:48:01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  search_word                                        description  \\\n",
       "0     Siemens  15 Things You Didn't Know About SIEMENS | SUBS...   \n",
       "1     Siemens  From digitalisation to automation, weƒ??re cha...   \n",
       "2     Siemens  Are you interested in what Siemens does and wh...   \n",
       "3     Siemens  The most powerful HVDC transformer in the worl...   \n",
       "4     Siemens  Articolul complet pe site: https://cavaleria.r...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['Alux', 'Alux.com', 'Alux Youtube', 'luxury l...   \n",
       "1  ['Siemens', 'Siemens UK', 'careers', 'jobs', '...   \n",
       "2  ['SIEMENS', 'products', 'Energy', 'Healthcare'...   \n",
       "3  ['Siemens', 'HVDC', 'Transformer', '1100kV', '...   \n",
       "4  ['Cavaleria.ro', 'hacking', 'siemens', 'job', ...   \n",
       "\n",
       "                                               title                Age  \\\n",
       "0            15 Things You Didn't Know About SIEMENS  323 days 12:06:13   \n",
       "1                What is it like to work at Siemens?  372 days 04:41:10   \n",
       "2                  Siemens - More than just business 1917 days 12:52:59   \n",
       "3  Siemens presents: The first 1,100 kV HVDC Tran...   42 days 11:22:18   \n",
       "4  Ce ??nseamnŽŸ sŽŸ lucrezi la Siemens - Cavaler...    0 days 03:48:01   \n",
       "\n",
       "   view_bucket  \n",
       "0          2.0  \n",
       "1          1.0  \n",
       "2          5.0  \n",
       "3          4.0  \n",
       "4          1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df['description'] = word_df['description'].astype(str)\n",
    "word_df['tags'] = word_df['tags'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "exp1_df = pd.DataFrame()\n",
    "exp1_df['title_char_count'] = word_df['title'].apply(len)\n",
    "exp1_df['title_word_count'] = word_df['title'].apply(lambda x: len(x.split()))\n",
    "exp1_df['title_word_density'] = exp1_df['title_char_count'] / (exp1_df['title_word_count']+1)\n",
    "exp1_df['title_punctuation_count'] = word_df['title'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "exp1_df['title_title_word_count'] = word_df['title'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "exp1_df['title_upper_case_word_count'] = word_df['title'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1_df['desc_char_count'] = word_df['description'].apply(len)\n",
    "exp1_df['desc_word_count'] = word_df['description'].apply(lambda x: len(x.split()))\n",
    "exp1_df['desc_word_density'] = exp1_df['desc_char_count'] / (exp1_df['desc_word_count']+1)\n",
    "exp1_df['desc_punctuation_count'] = word_df['description'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "exp1_df['desc_title_word_count'] = word_df['description'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "exp1_df['desc_upper_case_word_count'] = word_df['description'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosen to exclude Punctuation count for tags list since this column is a list format\n",
    "exp1_df['tags_char_count'] = word_df['tags'].apply(len)\n",
    "exp1_df['tags_word_count'] = word_df['tags'].apply(lambda x: len(x.split()))\n",
    "exp1_df['tags_word_density'] = exp1_df['tags_char_count'] / (exp1_df['tags_word_count']+1)\n",
    "exp1_df['tags_title_word_count'] = word_df['tags'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "exp1_df['desc_upper_case_word_count'] = word_df['tags'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_char_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>title_word_density</th>\n",
       "      <th>title_punctuation_count</th>\n",
       "      <th>title_title_word_count</th>\n",
       "      <th>title_upper_case_word_count</th>\n",
       "      <th>desc_char_count</th>\n",
       "      <th>desc_word_count</th>\n",
       "      <th>desc_word_density</th>\n",
       "      <th>desc_punctuation_count</th>\n",
       "      <th>desc_title_word_count</th>\n",
       "      <th>desc_upper_case_word_count</th>\n",
       "      <th>tags_char_count</th>\n",
       "      <th>tags_word_count</th>\n",
       "      <th>tags_word_density</th>\n",
       "      <th>tags_title_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2589</td>\n",
       "      <td>238</td>\n",
       "      <td>10.832636</td>\n",
       "      <td>242</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>514</td>\n",
       "      <td>57</td>\n",
       "      <td>8.862069</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>535</td>\n",
       "      <td>81</td>\n",
       "      <td>6.524390</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>15</td>\n",
       "      <td>10.125000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "      <td>46</td>\n",
       "      <td>6.234043</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>14</td>\n",
       "      <td>10.733333</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>10</td>\n",
       "      <td>6.181818</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>362</td>\n",
       "      <td>49</td>\n",
       "      <td>7.240000</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>9</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "      <td>14</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>21</td>\n",
       "      <td>9.272727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title_char_count  title_word_count  title_word_density  \\\n",
       "0                39                 7            4.875000   \n",
       "1                35                 8            3.888889   \n",
       "2                33                 6            4.714286   \n",
       "3                68                10            6.181818   \n",
       "4                51                 8            5.666667   \n",
       "\n",
       "   title_punctuation_count  title_title_word_count  \\\n",
       "0                        1                       4   \n",
       "1                        1                       2   \n",
       "2                        1                       2   \n",
       "3                        4                       3   \n",
       "4                        4                       2   \n",
       "\n",
       "   title_upper_case_word_count  desc_char_count  desc_word_count  \\\n",
       "0                            1             2589              238   \n",
       "1                            0              535               81   \n",
       "2                            0              293               46   \n",
       "3                            1              362               49   \n",
       "4                            0              207               14   \n",
       "\n",
       "   desc_word_density  desc_punctuation_count  desc_title_word_count  \\\n",
       "0          10.832636                     242                     61   \n",
       "1           6.524390                      24                      7   \n",
       "2           6.234043                       5                      6   \n",
       "3           7.240000                      16                      3   \n",
       "4          13.800000                      34                      4   \n",
       "\n",
       "   desc_upper_case_word_count  tags_char_count  tags_word_count  \\\n",
       "0                           0              514               57   \n",
       "1                           1              162               15   \n",
       "2                           1              161               14   \n",
       "3                           1               96                9   \n",
       "4                           0              204               21   \n",
       "\n",
       "   tags_word_density  tags_title_word_count  \n",
       "0           8.862069                     11  \n",
       "1          10.125000                      2  \n",
       "2          10.733333                      5  \n",
       "3           9.600000                      4  \n",
       "4           9.272727                      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((890, 17), (99, 17))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(exp1_df[['title_char_count', 'title_word_count', 'title_word_density', 'title_punctuation_count',\n",
    "                                                             'title_title_word_count', 'title_upper_case_word_count', 'desc_char_count', 'desc_word_count',\n",
    "                                                             'desc_word_density', 'desc_punctuation_count', 'desc_title_word_count', 'desc_upper_case_word_count',\n",
    "                                                             'tags_char_count', 'tags_word_count', 'tags_word_density', 'tags_title_word_count', 'desc_upper_case_word_count']], \n",
    "                                                             word_df['view_bucket'], test_size=0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.30\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.35      0.97      0.52        31\n",
      "        2.0       0.00      0.00      0.00         6\n",
      "        3.0       0.00      0.00      0.00         6\n",
      "        4.0       0.00      0.00      0.00         4\n",
      "        5.0       0.00      0.00      0.00         3\n",
      "        6.0       0.00      0.00      0.00         1\n",
      "        7.0       0.00      0.00      0.00         4\n",
      "        9.0       0.00      0.00      0.00         3\n",
      "       11.0       0.00      0.00      0.00         2\n",
      "       12.0       0.00      0.00      0.00         1\n",
      "       13.0       0.00      0.00      0.00         2\n",
      "       16.0       0.00      0.00      0.00         1\n",
      "       17.0       0.00      0.00      0.00         1\n",
      "       19.0       0.00      0.00      0.00         1\n",
      "       20.0       0.00      0.00      0.00         1\n",
      "       25.0       0.00      0.00      0.00         1\n",
      "       26.0       0.00      0.00      0.00         0\n",
      "       29.0       0.00      0.00      0.00         2\n",
      "       32.0       0.00      0.00      0.00         2\n",
      "       36.0       0.00      0.00      0.00         1\n",
      "       41.0       0.00      0.00      0.00         1\n",
      "       42.0       0.00      0.00      0.00         1\n",
      "       44.0       0.00      0.00      0.00         1\n",
      "       45.0       0.00      0.00      0.00         0\n",
      "       54.0       0.00      0.00      0.00         1\n",
      "       55.0       0.00      0.00      0.00         1\n",
      "       56.0       0.00      0.00      0.00         1\n",
      "       64.0       0.00      0.00      0.00         1\n",
      "       67.0       0.00      0.00      0.00         0\n",
      "       97.0       0.00      0.00      0.00         2\n",
      "      129.0       0.00      0.00      0.00         1\n",
      "      146.0       0.00      0.00      0.00         1\n",
      "      151.0       0.00      0.00      0.00         1\n",
      "      158.0       0.00      0.00      0.00         1\n",
      "      172.0       0.00      0.00      0.00         1\n",
      "      214.0       0.00      0.00      0.00         1\n",
      "      246.0       0.00      0.00      0.00         0\n",
      "      280.0       0.00      0.00      0.00         0\n",
      "      364.0       0.00      0.00      0.00         0\n",
      "      369.0       0.00      0.00      0.00         1\n",
      "      467.0       0.00      0.00      0.00         0\n",
      "      492.0       0.00      0.00      0.00         1\n",
      "      515.0       0.00      0.00      0.00         1\n",
      "      531.0       0.00      0.00      0.00         1\n",
      "      543.0       0.00      0.00      0.00         1\n",
      "      596.0       0.00      0.00      0.00         1\n",
      "      599.0       0.00      0.00      0.00         1\n",
      "      634.0       0.00      0.00      0.00         0\n",
      "      684.0       0.00      0.00      0.00         1\n",
      "      692.0       0.00      0.00      0.00         0\n",
      "      789.0       0.00      0.00      0.00         0\n",
      "      907.0       0.00      0.00      0.00         1\n",
      "     1142.0       0.00      0.00      0.00         0\n",
      "     1621.0       0.00      0.00      0.00         0\n",
      "     1909.0       0.00      0.00      0.00         0\n",
      "     2175.0       0.00      0.00      0.00         1\n",
      "     2191.0       0.00      0.00      0.00         1\n",
      "     3168.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.11      0.30      0.16        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z002xczx\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\z002xczx\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.30303030303030304\n",
      "Dismal performance from these features.  Moving on to experiment 2: count vectorizer\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ' + str(np.mean(y_pred == y_test)))\n",
    "print('Dismal performance from these features.  Moving on to experiment 2: count vectorizer and tfidf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(989, 2801)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# count_vect = CountVectorizer()\n",
    "# X_train_title = count_vect.fit_transform(word_df['title'])\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_train_tfidf_title = tfidf_transformer.fit_transform(X_train_title)\n",
    "# X_train_tfidf_title.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(989, 23)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_search = count_vect.fit_transform(word_df['search_word'])\n",
    "# X_train_tfidf_search = tfidf_transformer.fit_transform(X_train_search)\n",
    "# X_train_tfidf_search.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(989, 21238)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_description = count_vect.fit_transform(word_df['description'])\n",
    "# X_train_tfidf_description = tfidf_transformer.fit_transform(X_train_description)\n",
    "# X_train_tfidf_description.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(989, 6984)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_tags = count_vect.fit_transform(word_df['tags'])\n",
    "# X_train_tfidf_tags = tfidf_transformer.fit_transform(X_train_tags)\n",
    "# X_train_tfidf_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>search</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.10421281640261512, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                         description  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.10421281640261512, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                              search  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                tags  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate to build one huge DF  add up all side by side.   don't make each data frame column.  that is fundamentally\n",
    "df = pd.DataFrame()\n",
    "df['title'] = X_train_tfidf_title.toarray().tolist()\n",
    "df['description'] = X_train_tfidf_description.toarray().tolist()\n",
    "df['search'] = X_train_tfidf_search.toarray().tolist()\n",
    "df['tags'] = X_train_tfidf_tags.toarray().tolist()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((890, 4), (99, 4))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['title','description','search','tags']], word_df['view_bucket'], test_size=0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(890, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               words\n",
      "0  Siemens 15 Things You Didn't Know About SIEMEN...\n",
      "1  Siemens What is it like to work at Siemens? Fr...\n",
      "2  Siemens Siemens - More than just business Are ...\n",
      "3  Siemens Siemens presents: The first 1,100 kV H...\n",
      "4  Siemens Ce ??nseamnŽŸ sŽŸ lucrezi la Siemens -...\n"
     ]
    }
   ],
   "source": [
    "# scikit learn is particular about dimension handling so create one single column data frame with all words\n",
    "single_df = pd.DataFrame()\n",
    "single_df['words'] = word_df['search_word'] + ' ' + word_df[\"title\"] + ' ' + word_df[\"description\"] + ' ' + word_df['tags']\n",
    "print(single_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_df_tfidf = pd.DataFrame()\n",
    "# single_df_count = count_vect.fit_transform(single_df['words'])\n",
    "# single_df_tfidf = tfidf_transformer.fit_transform(single_df_count)\n",
    "# # single_df_tfidf = exp1_df.join(single_df_tfidf)\n",
    "\n",
    "# print(exp1_df['desc_word_count'].shape)\n",
    "# print(single_df_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((890, 23769), (99, 23769))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(single_df, word_df['view_bucket'], test_size=0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilize pipeline to make this process easier going forward\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_logreg = Pipeline([\n",
    "                     ('logreg', LogisticRegression(C=1, random_state=42))\n",
    "                    ])\n",
    "text_logreg = text_logreg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Log Reg TFIDF Transformer: 0.3434343434343434\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted = text_logreg.predict(X_test)\n",
    "print('Accuracy of Log Reg TFIDF Transformer: ' + str(np.mean(predicted == y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_clf = Pipeline([\n",
    "\n",
    "                     ('clf', MultinomialNB())\n",
    "                    ])\n",
    "text_clf = text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MutlinomialNB: 0.3434343434343434\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "print('Accuracy of MutlinomialNB: ' + str(np.mean(predicted == y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is slightly better than count based features Log Reg model\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy is slightly better than count based features Log Reg model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z002xczx\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([\n",
    "\n",
    "                       ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                         alpha=1e-3, n_iter=5, random_state=42)),\n",
    "                       ])\n",
    "_ = text_clf_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM algorithm: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "print('Accuracy of SVM algorithm: ' + str(np.mean(predicted_svm == y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy is worse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of knn: 0.3434343434343434\n"
     ]
    }
   ],
   "source": [
    "# consider using tfidvectorizer    no need to to use tfidtransformer.   use either countvectorizer or tfidvectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "text_knn = Pipeline([\n",
    "                     ('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('knn', KNeighborsClassifier(n_neighbors=20) )\n",
    "                    ])\n",
    "text_knn = text_knn.fit(X_train, y_train)\n",
    "\n",
    " \n",
    "predicted = text_knn.predict(X_test)\n",
    "print('Accuracy of knn: ' + str(np.mean(predicted == y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy so far with KNN\n"
     ]
    }
   ],
   "source": [
    "print('Best accuracy so far with KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of initial Random Forest: 0.32323232323232326\n"
     ]
    }
   ],
   "source": [
    "# Try Random Forest initially without parameter tuning \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "text_rf = Pipeline([\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('rf', RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)) \n",
    "                    ])\n",
    "text_rf = text_rf.fit(X_train, y_train)\n",
    "\n",
    "predicted = text_rf.predict(X_test)\n",
    "print('Accuracy of initial Random Forest: ' + str(np.mean(predicted == y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of initial XGBoost: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Try XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "text_xgb = Pipeline([\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('xgb', xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)) \n",
    "                    ])\n",
    "text_xgb = text_xgb.fit(X_train, y_train)\n",
    "\n",
    "predicted = text_xgb.predict(X_test)\n",
    "print('Accuracy of initial XGBoost: ' + str(np.mean(predicted == y_test)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
