{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z002xczx\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 989 entries, 0 to 999\n",
      "Data columns (total 14 columns):\n",
      "search_word                  989 non-null object\n",
      "contentDetails.caption       989 non-null bool\n",
      "contentDetails.definition    989 non-null object\n",
      "catID                        989 non-null int64\n",
      "description                  975 non-null object\n",
      "localized.description        974 non-null object\n",
      "localized.title              989 non-null object\n",
      "tags                         930 non-null object\n",
      "title                        989 non-null object\n",
      "commentCount                 989 non-null float64\n",
      "dislikeCount                 989 non-null float64\n",
      "likeCount                    989 non-null float64\n",
      "view_bucket                  989 non-null float64\n",
      "date                         989 non-null datetime64[ns, UTC]\n",
      "dtypes: bool(1), datetime64[ns, UTC](1), float64(4), int64(1), object(7)\n",
      "memory usage: 109.1+ KB\n",
      "None\n",
      "(989, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z002xczx\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#Split and scale the data, train hyper parameters, Model, Evaluate\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import cross_validation, metrics  \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "%store -r df\n",
    "\n",
    "print(df.info())\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(989, 3)\n",
      "(989, 3)\n"
     ]
    }
   ],
   "source": [
    "minmax_scale = preprocessing.MinMaxScaler().fit(df[['commentCount','dislikeCount','likeCount']])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = pd.DataFrame(minmax_scale.transform(df[['commentCount','dislikeCount','likeCount']]))\n",
    "print(X.shape)\n",
    "Y = df['view_bucket']\n",
    "\n",
    "n = pd.get_dummies(df[['search_word','contentDetails.definition','contentDetails.caption']])\n",
    "\n",
    "# X = pd.concat([X, n], axis=1)\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(989, 26)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = pd.concat([X, n], axis=1)\n",
    "X = pd.DataFrame(np.hstack([X,n]))\n",
    "X.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(989, 27)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the time series data and store as new date column\n",
    "ts = df['date']\n",
    "scaled_ts = (ts-ts.min())/(ts.max()-ts.min())\n",
    "\n",
    "X['date'] = pd.Series(scaled_ts)\n",
    "X['date'].fillna((X['date'].mean()), inplace=True)\n",
    "\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z002xczx\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 890 entries, 304 to 684\n",
      "Data columns (total 27 columns):\n",
      "0       890 non-null object\n",
      "1       890 non-null object\n",
      "2       890 non-null object\n",
      "3       890 non-null object\n",
      "4       890 non-null object\n",
      "5       890 non-null object\n",
      "6       890 non-null object\n",
      "7       890 non-null object\n",
      "8       890 non-null object\n",
      "9       890 non-null object\n",
      "10      890 non-null object\n",
      "11      890 non-null object\n",
      "12      890 non-null object\n",
      "13      890 non-null object\n",
      "14      890 non-null object\n",
      "15      890 non-null object\n",
      "16      890 non-null object\n",
      "17      890 non-null object\n",
      "18      890 non-null object\n",
      "19      890 non-null object\n",
      "20      890 non-null object\n",
      "21      890 non-null object\n",
      "22      890 non-null object\n",
      "23      890 non-null object\n",
      "24      890 non-null object\n",
      "25      890 non-null object\n",
      "date    890 non-null float64\n",
      "dtypes: float64(1), object(26)\n",
      "memory usage: 194.7+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=.9, random_state=0)\n",
    "\n",
    "X_train.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.722\n",
      "Model:                            OLS   Adj. R-squared:                  0.713\n",
      "Method:                 Least Squares   F-statistic:                     89.54\n",
      "Date:                Thu, 27 Dec 2018   Prob (F-statistic):          5.96e-220\n",
      "Time:                        18:56:29   Log-Likelihood:                -6136.2\n",
      "No. Observations:                 890   AIC:                         1.232e+04\n",
      "Df Residuals:                     864   BIC:                         1.245e+04\n",
      "Df Model:                          25                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "0          -1771.5925    300.587     -5.894      0.000   -2361.558   -1181.627\n",
      "1           4310.9950    225.988     19.076      0.000    3867.446    4754.544\n",
      "2           2371.4207    315.554      7.515      0.000    1752.078    2990.764\n",
      "3              8.3266     24.492      0.340      0.734     -39.744      56.397\n",
      "4            -15.8665     35.480     -0.447      0.655     -85.504      53.771\n",
      "5             34.3394     36.787      0.933      0.351     -37.863     106.541\n",
      "6            -38.3425     35.890     -1.068      0.286    -108.785      32.100\n",
      "7              0.0674     36.767      0.002      0.999     -72.096      72.231\n",
      "8            219.5733     41.656      5.271      0.000     137.814     301.332\n",
      "9            -44.3046     35.609     -1.244      0.214    -114.194      25.585\n",
      "10            10.7608     36.362      0.296      0.767     -60.608      82.130\n",
      "11           -29.9639     37.139     -0.807      0.420    -102.857      42.929\n",
      "12           -17.7907     37.243     -0.478      0.633     -90.888      55.306\n",
      "13           -16.4434     36.373     -0.452      0.651     -87.832      54.946\n",
      "14            27.7905     36.323      0.765      0.444     -43.502      99.083\n",
      "15           -10.9677     36.586     -0.300      0.764     -82.776      60.841\n",
      "16           -14.9244     36.639     -0.407      0.684     -86.835      56.987\n",
      "17            30.8180     34.936      0.882      0.378     -37.751      99.387\n",
      "18           105.3818     46.510      2.266      0.024      14.097     196.667\n",
      "19            45.7970     36.409      1.258      0.209     -25.663     117.257\n",
      "20           -11.8136     35.570     -0.332      0.740     -81.628      58.001\n",
      "21            -4.7630     38.002     -0.125      0.900     -79.351      69.825\n",
      "22            10.4114     35.341      0.295      0.768     -58.953      79.776\n",
      "23           -35.1025     35.794     -0.981      0.327    -105.357      35.152\n",
      "24            87.9484     56.962      1.544      0.123     -23.852     199.749\n",
      "25           156.7084     63.111      2.483      0.013      32.840     280.576\n",
      "date         -82.9934     66.396     -1.250      0.212    -213.310      47.324\n",
      "==============================================================================\n",
      "Omnibus:                      423.292   Durbin-Watson:                   1.986\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           453642.763\n",
      "Skew:                          -0.542   Prob(JB):                         0.00\n",
      "Kurtosis:                     113.598   Cond. No.                     2.25e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 3.26e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = sm.OLS(list(y_train), X_train.astype(float)).fit()\n",
    "predictions = model.predict(X) \n",
    " \n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R squared: 0.7739\n",
      "Linear Regression RMSE: 323.3618\n",
      "Linear Regression MAE: 117.6755\n"
     ]
    }
   ],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "print('Linear Regression R squared: %.4f' % regressor.score(X_test, y_test))\n",
    "\n",
    "lin_mse = mean_squared_error(y_pred, y_test)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print('Linear Regression RMSE: %.4f' % lin_rmse)\n",
    "\n",
    "lin_mae = mean_absolute_error(y_pred, y_test)\n",
    "print('Linear Regression MAE: %.4f' % lin_mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors=list(X_train)\n",
    "# feat_imp = pd.Series(regressor.feature_importances_, predictors).sort_values(ascending=False)\n",
    "# feat_imp.plot(kind='bar', title='Importance of Features')\n",
    "# plt.ylabel('Feature Importance Score')\n",
    "# print('Accuracy of the linear regression model on test set: {:.3f}'.format(regressor.score(X_test, y_test)))\n",
    "# pred=regressor.predict(X_test)\n",
    "# print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try random forest with default hyperparameters\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "forest_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R squared: 0.2743\n",
      "Random Forest RMSE: 579.3618\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest R squared: %.4f' % forest_reg.score(X_test, y_test))\n",
    "y_pred = forest_reg.predict(X_test)\n",
    "forest_mse = mean_squared_error(y_pred, y_test)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print('Random Forest RMSE: %.4f' % forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and select optimal hyperparameters\n",
    "print(forest_reg.get_params())\n",
    "\n",
    "#Create a random grid for possible parameters to attempt and then use random search\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, scoring = 'neg_mean_squared_error', n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1600, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 10, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "#Print and evaluate best parameters from the search\n",
    "print(rf_random.best_params_)\n",
    "\n",
    "best_random = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate performance of the base model w/ searched hyperparameters\n",
    "\n",
    "random_model = RandomForestRegressor(n_estimators = 200, min_samples_split=2, min_samples_leaf=1, \n",
    "                                   max_features = 'sqrt', max_depth = 50, bootstrap = True, random_state = 42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=50,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R squared: 0.7320\n",
      "Random Forest RMSE: 352.0735\n"
     ]
    }
   ],
   "source": [
    "#Evaluate performance of random forest with random searched hyperparameters\n",
    "print('Random Forest R squared: %.4f' % random_model.score(X_test, y_test))\n",
    "y_pred = random_model.predict(X_test)\n",
    "forest_mse = mean_squared_error(y_pred, y_test)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print('Random Forest RMSE: %.4f' % forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try Grid Search to see if we can improve the hyperparameters further. \n",
    "# Setting grid around the previously identified optimal values\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [30, 40, 50, 60, 70],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, scoring = 'neg_mean_squared_error',\n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 480 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 60,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R squared: -116234.1245\n",
      "Random Forest RMSE: 340.9313\n"
     ]
    }
   ],
   "source": [
    "#Evaluate performance of random forest with grid search hyperparameters\n",
    "print('Random Forest R squared: %.4f' % grid_search.score(X_test, y_test))\n",
    "y_pred = grid_search.predict(X_test)\n",
    "forest_mse = mean_squared_error(y_pred, y_test)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print('Random Forest RMSE: %.4f' % forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try Gradient Boosting\n",
    "model = ensemble.GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting R squared\": 0.0033\n",
      "Gradient Boosting RMSE: 678.9475\n"
     ]
    }
   ],
   "source": [
    "print('Gradient Boosting R squared\": %.4f' % model.score(X_test, y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "model_mse = mean_squared_error(y_pred, y_test)\n",
    "model_rmse = np.sqrt(model_mse)\n",
    "print('Gradient Boosting RMSE: %.4f' % model_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.9, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'ls', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'presort': 'auto', 'random_state': None, 'subsample': 1.0, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [100, 311, 522, 733, 944, 1155, 1366, 1577, 1788, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 10, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [100, 311, 522, 733, 944, 1155, 1366, 1577, 1788, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic GBM Regressor performance was poor - try tuning learning rate and number of trees\n",
    "gbm = GradientBoostingRegressor()\n",
    "\n",
    "gbm_random = RandomizedSearchCV(estimator = gbm, param_distributions = random_grid, scoring = 'neg_mean_squared_error', n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "gbm_random.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "#Print and evaluate best parameters from the search\n",
    "print(gbm_random.best_params_)\n",
    "\n",
    "best_random = gbm_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate performance of the base model w/ searched hyperparameters\n",
    "\n",
    "random_model = RandomForestRegressor(n_estimators = 1788, min_samples_split=10, min_samples_leaf=1, \n",
    "                                   max_features = 'sqrt', max_depth = 3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=10,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1788, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM - random searched R squared: 0.6714\n",
      "GBM - random searched RMSE: 389.8599\n"
     ]
    }
   ],
   "source": [
    "#Evaluate performance of random forest with random searched hyperparameters\n",
    "print('GBM - random searched R squared: %.4f' % random_model.score(X_test, y_test))\n",
    "y_pred = random_model.predict(X_test)\n",
    "forest_mse = mean_squared_error(y_pred, y_test)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print('GBM - random searched RMSE: %.4f' % forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the GBM on test set: 0.671\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mix type of y not allowed, got types {'multiclass', 'continuous'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-b2c07fd2d813>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy of the GBM on test set: {:.3f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits)\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1421\u001b[1;33m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1422\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys_types\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mix type of y not allowed, got types %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mys_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0mlabel_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mys_types\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Mix type of y not allowed, got types {'multiclass', 'continuous'}"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictors=list(X_train)\n",
    "feat_imp = pd.Series(random_model.feature_importances_, predictors).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Importance of Features')\n",
    "plt.ylabel('Feature Importance Score')\n",
    "print('Accuracy of the GBM on test set: {:.3f}'.format(random_model.score(X_test, y_test)))\n",
    "pred=random_model.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
