{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z002xczx\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\z002xczx\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 989 entries, 0 to 999\n",
      "Data columns (total 16 columns):\n",
      "search_word                  989 non-null object\n",
      "contentDetails.caption       989 non-null bool\n",
      "contentDetails.definition    989 non-null object\n",
      "catID                        989 non-null int64\n",
      "description                  975 non-null object\n",
      "localized.description        974 non-null object\n",
      "localized.title              989 non-null object\n",
      "tags                         930 non-null object\n",
      "title                        989 non-null object\n",
      "commentCount                 989 non-null float64\n",
      "dislikeCount                 989 non-null float64\n",
      "likeCount                    989 non-null float64\n",
      "view_bucket                  989 non-null float64\n",
      "date                         989 non-null datetime64[ns, UTC]\n",
      "Aging                        989 non-null datetime64[ns]\n",
      "Age                          989 non-null timedelta64[ns]\n",
      "dtypes: bool(1), datetime64[ns, UTC](1), datetime64[ns](1), float64(4), int64(1), object(7), timedelta64[ns](1)\n",
      "memory usage: 124.6+ KB\n",
      "None\n",
      "(989, 16)\n"
     ]
    }
   ],
   "source": [
    "#Split and scale the data, train hyper parameters, Model, Evaluate\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import cross_validation, metrics  \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "%store -r df\n",
    "\n",
    "print(df.info())\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(989, 3)\n",
      "(989, 3)\n"
     ]
    }
   ],
   "source": [
    "minmax_scale = preprocessing.MinMaxScaler().fit(df[['commentCount','dislikeCount','likeCount']])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = pd.DataFrame(minmax_scale.transform(df[['commentCount','dislikeCount','likeCount']]))\n",
    "print(X.shape)\n",
    "Y = df['view_bucket']\n",
    "\n",
    "n = pd.get_dummies(df[['search_word','contentDetails.definition','contentDetails.caption']])\n",
    "\n",
    "# X = pd.concat([X, n], axis=1)\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(989, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = pd.concat([X, n], axis=1)\n",
    "X = pd.DataFrame(np.hstack([X,n]))\n",
    "X.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(989, 27)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the time series data and store as new date column\n",
    "ts = df['Age']\n",
    "scaled_ts = (ts-ts.min())/(ts.max()-ts.min())\n",
    "\n",
    "X['Age'] = pd.Series(scaled_ts)\n",
    "X['Age'].fillna((X['Age'].mean()), inplace=True)\n",
    "\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000190146</td>\n",
       "      <td>0.000486296</td>\n",
       "      <td>0.000165565</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0186383</td>\n",
       "      <td>4.25509e-05</td>\n",
       "      <td>1.24485e-05</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0186383</td>\n",
       "      <td>0.000316092</td>\n",
       "      <td>0.000129998</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0186383</td>\n",
       "      <td>0.00124005</td>\n",
       "      <td>0.000681999</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000104011</td>\n",
       "      <td>0.00013981</td>\n",
       "      <td>0.000127686</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0            1            2      3  4  5  6  7  8  9    ...     \\\n",
       "0  0.000190146  0.000486296  0.000165565  False  1  0  0  0  0  0    ...      \n",
       "1    0.0186383  4.25509e-05  1.24485e-05  False  1  0  0  0  0  0    ...      \n",
       "2    0.0186383  0.000316092  0.000129998  False  1  0  0  0  0  0    ...      \n",
       "3    0.0186383   0.00124005  0.000681999  False  1  0  0  0  0  0    ...      \n",
       "4  0.000104011   0.00013981  0.000127686  False  1  0  0  0  0  0    ...      \n",
       "\n",
       "  17 18 19 20 21 22 23 24 25       Age  \n",
       "0  0  0  0  0  0  0  0  1  0  0.083642  \n",
       "1  0  0  0  0  0  0  0  1  0  0.095886  \n",
       "2  0  0  0  0  0  0  0  1  0  0.484491  \n",
       "3  0  0  0  0  0  0  0  1  0  0.012972  \n",
       "4  0  0  0  0  0  0  0  1  0  0.002331  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 890 entries, 304 to 684\n",
      "Data columns (total 27 columns):\n",
      "0      890 non-null object\n",
      "1      890 non-null object\n",
      "2      890 non-null object\n",
      "3      890 non-null object\n",
      "4      890 non-null object\n",
      "5      890 non-null object\n",
      "6      890 non-null object\n",
      "7      890 non-null object\n",
      "8      890 non-null object\n",
      "9      890 non-null object\n",
      "10     890 non-null object\n",
      "11     890 non-null object\n",
      "12     890 non-null object\n",
      "13     890 non-null object\n",
      "14     890 non-null object\n",
      "15     890 non-null object\n",
      "16     890 non-null object\n",
      "17     890 non-null object\n",
      "18     890 non-null object\n",
      "19     890 non-null object\n",
      "20     890 non-null object\n",
      "21     890 non-null object\n",
      "22     890 non-null object\n",
      "23     890 non-null object\n",
      "24     890 non-null object\n",
      "25     890 non-null object\n",
      "Age    890 non-null float64\n",
      "dtypes: float64(1), object(26)\n",
      "memory usage: 194.7+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z002xczx\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=.9, random_state=0)\n",
    "\n",
    "X_train.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.722\n",
      "Model:                            OLS   Adj. R-squared:                  0.713\n",
      "Method:                 Least Squares   F-statistic:                     89.54\n",
      "Date:                Thu, 10 Jan 2019   Prob (F-statistic):          5.96e-220\n",
      "Time:                        17:03:51   Log-Likelihood:                -6136.2\n",
      "No. Observations:                 890   AIC:                         1.232e+04\n",
      "Df Residuals:                     864   BIC:                         1.245e+04\n",
      "Df Model:                          25                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "0          -1771.5925    300.587     -5.894      0.000   -2361.558   -1181.627\n",
      "1           4310.9950    225.988     19.076      0.000    3867.446    4754.544\n",
      "2           2371.4207    315.554      7.515      0.000    1752.078    2990.764\n",
      "3              8.3266     24.492      0.340      0.734     -39.744      56.397\n",
      "4            -23.4114     36.737     -0.637      0.524     -95.515      48.692\n",
      "5             26.7945     36.322      0.738      0.461     -44.495      98.084\n",
      "6            -45.8873     35.392     -1.297      0.195    -115.351      23.577\n",
      "7             -7.4775     36.159     -0.207      0.836     -78.448      63.493\n",
      "8            212.0284     41.385      5.123      0.000     130.802     293.255\n",
      "9            -51.8495     34.797     -1.490      0.137    -120.147      16.448\n",
      "10             3.2160     35.406      0.091      0.928     -66.276      72.708\n",
      "11           -37.5088     36.246     -1.035      0.301    -108.650      33.633\n",
      "12           -25.3356     36.265     -0.699      0.485     -96.514      45.843\n",
      "13           -23.9883     35.298     -0.680      0.497     -93.267      45.291\n",
      "14            20.2457     35.559      0.569      0.569     -49.546      90.038\n",
      "15           -18.5125     35.612     -0.520      0.603     -88.410      51.384\n",
      "16           -22.4693     35.456     -0.634      0.526     -92.059      47.121\n",
      "17            23.2731     34.931      0.666      0.505     -45.286      91.833\n",
      "18            97.8369     46.615      2.099      0.036       6.344     189.329\n",
      "19            38.2522     36.117      1.059      0.290     -32.634     109.139\n",
      "20           -19.3584     34.648     -0.559      0.576     -87.362      48.645\n",
      "21           -12.3078     36.942     -0.333      0.739     -84.815      60.199\n",
      "22             2.8665     35.559      0.081      0.936     -66.925      72.658\n",
      "23           -42.6474     37.514     -1.137      0.256    -116.276      30.981\n",
      "24            12.4998     10.561      1.184      0.237      -8.229      33.229\n",
      "25            81.2598     31.753      2.559      0.011      18.937     143.583\n",
      "Age           82.9934     66.396      1.250      0.212     -47.324     213.310\n",
      "==============================================================================\n",
      "Omnibus:                      423.292   Durbin-Watson:                   1.986\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           453642.763\n",
      "Skew:                          -0.542   Prob(JB):                         0.00\n",
      "Kurtosis:                     113.598   Cond. No.                     2.25e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.79e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = sm.OLS(list(y_train), X_train.astype(float)).fit()\n",
    "predictions = model.predict(X) \n",
    " \n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R squared: 0.7738\n",
      "Linear Regression RMSE: 323.4607\n",
      "Linear Regression MAE: 117.6629\n"
     ]
    }
   ],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "print('Linear Regression R squared: %.4f' % regressor.score(X_test, y_test))\n",
    "\n",
    "lin_mse = mean_squared_error(y_pred, y_test)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print('Linear Regression RMSE: %.4f' % lin_rmse)\n",
    "\n",
    "lin_mae = mean_absolute_error(y_pred, y_test)\n",
    "print('Linear Regression MAE: %.4f' % lin_mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors=list(X_train)\n",
    "# feat_imp = pd.Series(regressor.feature_importances_, predictors).sort_values(ascending=False)\n",
    "# feat_imp.plot(kind='bar', title='Importance of Features')\n",
    "# plt.ylabel('Feature Importance Score')\n",
    "# print('Accuracy of the linear regression model on test set: {:.3f}'.format(regressor.score(X_test, y_test)))\n",
    "# pred=regressor.predict(X_test)\n",
    "# print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try random forest with default hyperparameters\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "forest_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R squared: 0.2962\n",
      "Random Forest RMSE: 570.5359\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest R squared: %.4f' % forest_reg.score(X_test, y_test))\n",
    "y_pred = forest_reg.predict(X_test)\n",
    "forest_mse = mean_squared_error(y_pred, y_test)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print('Random Forest RMSE: %.4f' % forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and select optimal hyperparameters\n",
    "print(forest_reg.get_params())\n",
    "\n",
    "#Create a random grid for possible parameters to attempt and then use random search\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, scoring = 'neg_mean_squared_error', n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "#Print and evaluate best parameters from the search\n",
    "print(rf_random.best_params_)\n",
    "\n",
    "best_random = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate performance of the base model w/ searched hyperparameters\n",
    "\n",
    "random_model = RandomForestRegressor(n_estimators = 200, min_samples_split=2, min_samples_leaf=1, \n",
    "                                   max_features = 'sqrt', max_depth = 50, bootstrap = True, random_state = 42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=50,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R squared: 0.7378\n",
      "Random Forest RMSE: 348.2245\n"
     ]
    }
   ],
   "source": [
    "#Evaluate performance of random forest with random searched hyperparameters\n",
    "print('Random Forest R squared: %.4f' % random_model.score(X_test, y_test))\n",
    "y_pred = random_model.predict(X_test)\n",
    "forest_mse = mean_squared_error(y_pred, y_test)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print('Random Forest RMSE: %.4f' % forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try Grid Search to see if we can improve the hyperparameters further. \n",
    "# Setting grid around the previously identified optimal values\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [30, 40, 50, 60, 70],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, scoring = 'neg_mean_squared_error',\n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 480 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 60,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R squared: -127897.2669\n",
      "Random Forest RMSE: 357.6273\n"
     ]
    }
   ],
   "source": [
    "#Evaluate performance of random forest with grid search hyperparameters\n",
    "print('Random Forest R squared: %.4f' % grid_search.score(X_test, y_test))\n",
    "y_pred = grid_search.predict(X_test)\n",
    "forest_mse = mean_squared_error(y_pred, y_test)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print('Random Forest RMSE: %.4f' % forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try Gradient Boosting\n",
    "model = ensemble.GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting R squared\": 0.0026\n",
      "Gradient Boosting RMSE: 679.1935\n"
     ]
    }
   ],
   "source": [
    "print('Gradient Boosting R squared\": %.4f' % model.score(X_test, y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "model_mse = mean_squared_error(y_pred, y_test)\n",
    "model_rmse = np.sqrt(model_mse)\n",
    "print('Gradient Boosting RMSE: %.4f' % model_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.9, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'ls', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'presort': 'auto', 'random_state': None, 'subsample': 1.0, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [100, 311, 522, 733, 944, 1155, 1366, 1577, 1788, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 10, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   43.3s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [100, 311, 522, 733, 944, 1155, 1366, 1577, 1788, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic GBM Regressor performance was poor - try tuning learning rate and number of trees\n",
    "gbm = GradientBoostingRegressor()\n",
    "\n",
    "gbm_random = RandomizedSearchCV(estimator = gbm, param_distributions = random_grid, scoring = 'neg_mean_squared_error', n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "gbm_random.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 9}\n"
     ]
    }
   ],
   "source": [
    "#Print and evaluate best parameters from the search\n",
    "print(gbm_random.best_params_)\n",
    "\n",
    "best_random = gbm_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate performance of the base model w/ searched hyperparameters\n",
    "\n",
    "random_model = GradientBoostingRegressor(n_estimators = 1788, min_samples_split=10, min_samples_leaf=1, \n",
    "                                   max_features = 'sqrt', max_depth = 3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=10,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=1788,\n",
       "             presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM - random searched R squared: 0.6732\n",
      "GBM - random searched RMSE: 388.7867\n"
     ]
    }
   ],
   "source": [
    "#Evaluate performance of GBM with random searched hyperparameters\n",
    "print('GBM - random searched R squared: %.4f' % random_model.score(X_test, y_test))\n",
    "y_pred = random_model.predict(X_test)\n",
    "forest_mse = mean_squared_error(y_pred, y_test)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print('GBM - random searched RMSE: %.4f' % forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the GBM on test set: 0.673\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAESCAYAAAAMifkAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XncHWV5//HPl0TWQFgVBUJYZZFFG8ACbmwGkaUKglZlU9SC2Kq/ij+p0EARbbXVghWsIEIREFoakUVkVVRIQCSEgISwJAKyBEgERAJX/7jvB4fjnDNznjxzMuT5vl+veT0z99wzc80855xrZu5ZFBGYmZn1ssySDsDMzNrPycLMzCo5WZiZWSUnCzMzq+RkYWZmlZwszMyskpOFWYtIer2kX0laKOnoJR2P2RAnCxtRku6TtNuSjgNA0rWSPrKk4+jT3wPXRsTKEfGNzpF5nf4g6feF7i8XZ4GSJkoKSWMXZz62dHOysKWOklfqZ3t9YGZFnaMiYlyh+8UgAuvmFb69rSb/g60xkg6RdIOkf5X0pKQ5knbM5XMlPSLp4EL970r6lqQr82mY6yStXxi/o6Rpkp7Kf3csjLtW0j9JugF4BjgbeAtwSt77PiXX+3pe9gJJN0t6S2Eex0u6QNL38vJnSppUGL+epP+W9Kikx4fmmccdJmmWpCckXVGMu2S77JPn/WSOe/NcfjXwjkLMm/a5vTfL226+pLskva8wbq98emtBXv/jC5Nen/8+OXSkkrfFOYXpX3b0UbK9N5Q0XtJ3JD0k6beSTpQ0JtffOP8/n5L0mKTz+1k3a4GIcOduxDrgPmC33H8IsAg4FBgDnAg8AJwKLAfsASwExuX6383Db83jvw78LI9bHXgC+BAwFnh/Hl4jj782z3vLPP5VuewjHfF9EFgj1/kM8DCwfB53PPAH4F053i8Bv8zjxgC/Bv4VWAlYHtg5j9sPmA1snud7LPDzLttnU+BpYPcc49/naZctrMdHemzf0vE5prl5W48F3gQ8BmyZx78d2Iq0g7g18DtgvzxuIhDA2ML8jgfOKQy/rE6X7X0xcFqO5dXATcDHcv3vA1/Iy39p27l75XQ+srCm3RsRZ0bEC8D5wHrAlIh4LiJ+DPwR2LhQ/0cRcX1EPEf6cflLSesBewF3R8TZEbEoIr4P3AnsXZj2uxExM49/viyYiDgnIh7Pdb5KSkqvL1T5WURcmuM9G9gml28PvA74fxHxdET8ISJ+lsd9DPhSRMyKiEXAScC2XY4uDszreGWO8V+AFYAdS+p28418VPKkpFty2buB+/K2XhQRtwAXAfvn9b42ImZExIsRcRvpx/ttfSyzzEvbm5TM9wT+Nm+fR0iJ9aBc93nSKbbXdWw7e4VwsrCm/a7Q/yxARHSWjSsMzx3qiYjfA/NJP9KvA+7vmPf9wDpl03Yj6TP5dNFTkp4ExgNrFqo8XOh/Blg+n3pZD7g//zB2Wh/4+tAPeI5ZHbENedl6RMSLOe6yut0cHRGr5u5NhRh2KCSRJ4G/BtbO672DpGvyKbSngI93rPdwFLf3+qSji4cKyz+NdIQB6QhKwE35FNxhi7lsGzBf/WBts95Qj6RxpD3WB3PXuac+Abi8MNz5COWXDef2ic8BuwIzI+JFSU+QfsSqzAUmSBpbkjDmAv8UEf9VYz4Pkk4HDcUk0jr/tsa0VfFdFxG7dxl/LnAKsGdE/EHSv/GnZFH26OmngRULw2uX1ClONxd4DlizLKFGxMPARwEk7Qz8RNL1ETG7xzpZi/jIwtrmXZJ2lrQscAJwY0TMBS4FNpX0AUljJR0IbAFc0mNevwM2LAyvTGpDeRQYK+mLwCo147oJeAg4WdJKkpaXtFMe9y3g85K2BMgNvQd0mc8FwF6SdpX0KlK7yXPAz2vG0c0lpO3zIUmvyt12Q43npHWfnxPF9sAHCtM+CrzIy7fVrcBbJU2QNB74fK+FR8RDwI+Br0paRdIykjaS9DYASQdIWjdXf4KUaF5YzHW2AXKysLY5FziOdCrnL0inUoiIx0nn5T8DPE46rfHuiHisx7y+Duyfr1D6BnAFcBnwG9KpoD9Q49RVXv4LpPaRjUkNu/NI7Q9ExP8AXwbOk7QAuJ10/r5sPneRGtn/ndQAvTewd0T8sU4cPeJbSLpg4CDS0cvDOablcpW/AaZIWgh8kZS0hqZ9Bvgn4IZ8CunNEXElqY3pNuBmeiflIR8GlgXuICWEC4HX5nHbATdK+j0wFfhURNw7/DW2QVOEX35k7SDpu8C8iDh2ScdiZi/nIwszM6vkZGFmZpUaPQ0laTLpvPEY4D8j4uSO8Z8GPsKfGh0Pi4j787gXgBm56gMRsU9jgZqZWU+NJYt8m/9vSHeqzgOmAe+PiDsKdd5ButrlGUmfAN4eEQfmcb+PiHElszYzswFr8jTU9sDsiJiTr/Q4D9i3WCEirslXYgD8ElgXMzNrnSZvyluHl1+WOA/YoUf9w0mXNQ5ZXtJ00imqkyPi4l4LW3PNNWPixInDDNXMbHS6+eabH4uItarqNZksyu6KLT3nJemDwCRe/qyaCRHxoKQNgaslzYiIezqmOwI4AmDChAlMnz59ZCI3MxslJHU+RqdUk6eh5lF4dAPpFNODnZWUXpTzBWCf/PA4ACLiwfx3DukJl2/snDYiTo+ISRExaa21KhOjmZkNU5PJYhqwiaQN8qMbDiLdufkSSW8kPWxsn/yUyqHy1SQtl/vXBHYi3RVqZmZLQGOnoSJikaSjSI9YGAOcEREzJU0BpkfEVOCfSU8c/UF6ntpLl8huDpwm6UVSQju5eBWVmZkN1lLzuI9JkyaF2yzMzPoj6eaImFRVz3dwm5lZJScLMzOr5GRhZmaVnCzMzKzSUvta1YnH/Ki0/L6T9xpwJGZmr3w+sjAzs0pOFmZmVsnJwszMKjlZmJlZpaW2gbtvx4/vUv7UYOMwM2shH1mYmVklJwszM6vkZGFmZpWcLMzMrJKThZmZVXKyMDOzSk4WZmZWycnCzMwqOVmYmVklJwszM6vkZGFmZpWcLMzMrJKThZmZVXKyMDOzSk4WZmZWycnCzMwqOVmYmVklJwszM6vkZGFmZpWcLMzMrJKThZmZVXKyMDOzSk4WZmZWaeySDuCVaquztuo6bsbBMwYYiZlZ8xo9spA0WdJdkmZLOqZk/Kcl3SHpNklXSVq/MO5gSXfn7uAm4zQzs94aSxaSxgCnAnsCWwDvl7RFR7VfAZMiYmvgQuAredrVgeOAHYDtgeMkrdZUrGZm1luTRxbbA7MjYk5E/BE4D9i3WCEiromIZ/LgL4F1c/87gSsjYn5EPAFcCUxuMFYzM+uhyWSxDjC3MDwvl3VzOHDZMKc1M7MGNdnArZKyKK0ofRCYBLytn2klHQEcATBhwoThRWlmZpVqH1lIWqnPec8D1isMrws8WDLf3YAvAPtExHP9TBsRp0fEpIiYtNZaa/UZnpmZ1VWZLCTtKOkOYFYe3kbSN2vMexqwiaQNJC0LHARM7Zj3G4HTSInikcKoK4A9JK2WG7b3yGVmZrYE1Dmy+FdSg/PjABHxa+CtVRNFxCLgKNKP/CzggoiYKWmKpH1ytX8GxgE/kHSrpKl52vnACaSEMw2YksvMzGwJqNVmERFzpZc1I7xQc7pLgUs7yr5Y6N+tx7RnAGfUWY6ZmTWrTrKYK2lHIPLppKPJp6TMzGx0qHMa6uPAkaRLV+cB2+ZhMzMbJXoeWeS7sD8UEX89oHjMzKyFeh5ZRMQLdNx1bWZmo0+dNosbJJ0CnA88PVQYEbc0FpWZmbVKnWSxY/47pVAWwC4jH46ZmbVRZbKIiHcMIhAzM2uvOndwj5f0NUnTc/dVSeMHEZyZmbVDnUtnzwAWAu/L3QLgzCaDMjOzdqnTZrFRRLy3MPyPkm5tKiAzM2ufOkcWz0raeWhA0k7As82FZGZmbVPnyOITwFmFdoongEMai8jMzFqnztVQtwLbSFolDy9oPCozM2uVOldDnSRp1YhYEBEL8jsmThxEcGZm1g512iz2jIgnhwYi4gngXc2FZGZmbVMnWYyRtNzQgKQVgOV61Dczs6VMnQbuc4CrJJ1JeszHYcBZjUZlZmatUqeB+yuSbgOG3mp3QkT4fdhmZqNI3deqXi5pGund2481G5KZmbVN1zYLSZdIekPufy1wO+kU1NmS/nZA8ZmZWQv0auDeICJuz/2HAldGxN7ADqSkYWZmo0SvZPF8oX9X4FKAiFgIvNhkUGZm1i692izmSvokMA94E3A5vHTp7KsGEJuZmbVEr2RxOOnteLsBBxZuzHszfkT5sMzabPPS8s3vnDXgSMzM+tM1WUTEI8DHS8qvAa5pMigzM2uXOndwm5nZKOdkYWZmlZwszMysUp1HlG8q6SpJt+fhrSUd23xoZmbWFnWOLL4NfJ5830VE3AYc1GRQZmbWLnWSxYoRcVNH2aImgjEzs3aqkywek7QR6fHkSNofeKjRqMzMrFXqPHX2SOB0YDNJvwXuBT7YaFRmZtYqdd5nMQfYTdJKwDL52VBmZjaK1Lka6iRJq0bE0xGxUNJqkk4cRHBmZtYOddos9iw8F4qIeAJ4V52ZS5os6S5JsyUdUzL+rZJukbQot4UUx70g6dbcTa2zPDMza0adNosxkpaLiOfgpafOLlc1kaQxwKnA7qQn106TNDUi7ihUewA4BPhsySyejYhta8RnZmYNq5MszgGuknQm6Yqow4Czaky3PTA7t3kg6TxgX+ClZBER9+Vxfj+GmVmL1Wng/oqkGaQXIAk4ISKuqDHvdYC5heF5pLfs1bW8pOmkezpOjoiLOytIOgI4AmDChAl9zNrMzPpR58iCiLgMuKzPeatsVn1MPyEiHpS0IXC1pBkRcU9HXKeTLutl0qRJ/czbzMz6UOdqqPdIulvSU5IWSFooaUGNec8D1isMrws8WDewiHgw/50DXAu8se60ZmY2supcDfUVYJ+IGB8Rq0TEyhGxSo3ppgGbSNpA0rKk50nVuqopX567XO5fE9iJQluHmZkNVp1k8buI6Pu9nxGxCDgKuAKYBVwQETMlTZG0D4Ck7STNAw4ATpM0M0++OTBd0q9Jb+U7ueMqKjMzG6A6bRbTJZ0PXAw8N1QYEf9dNWFEXApc2lH2xUL/NNLpqc7pfg5sVSM2MzMbgDrJYhXgGWCPQlkAlcnCzMyWDnUunT10EIGYmVl7VSYLScsDhwNbAssPlUfEYQ3GZWZmLVKngftsYG3gncB1pDYGP3nWzGwUqZMsNo6IfwCejoizgL1w47OZ2ahSJ1k8n/8+KekNwHhgYmMRmZlZ69S5Gup0SasBx5JuqhsH/EOjUZmZWavUSRZX5XdYXA9sCCBpg0ajMjOzVqlzGuqikrILRzoQMzNrr65HFpI2I10uO17SewqjVqFwCa2ZmS39ep2Gej3wbmBVYO9C+ULgo00GZWZm7dI1WUTE/0q6BPhcRJw0wJjMzKxlerZZRMQLpHdom5nZKFbnaqifSzoFOB94eqgwIm5pLCozM2uVOslix/x3SqEsgF1GPhwzM2ujOk+dfccgAjEzs/aq8w7u8ZK+Jml67r4qafwggjMzs3aoc1PeGaTLZd+XuwXAmU0GZWZm7VKnzWKjiHhvYfgfJd3aVEBmZtY+dY4snpW089CApJ2AZ5sLyczM2qbOkcUngLNyO4WA+cDBjUZlZmatUudqqFuBbSStkocXNB6VmZm1Sp2rodaQ9A3gWuAaSV+XtEbjkZmZWWvUabM4D3gUeC+wf+4/v8mgzMysXeq0WaweEScUhk+UtF9TAZmZWfvUObK4RtJBkpbJ3fuAHzUdmJmZtUedZPEx4Fzgj7k7D/i0pIWS3NhtZjYK1LkaauVBBGJmZu1Vp80CSVsDE4v1I+K/G4rJzMxapjJZSDoD2BqYCbyYiwNwsjAzGyXqHFm8OSK2aDwSMzNrrToN3L+Q5GRhZjaK1TmyOIuUMB4GniM9HyoiYutGIzMzs9aokyzOAD4EzOBPbRZmZjaK1DkN9UBETI2IeyPi/qGuzswlTZZ0l6TZko4pGf9WSbdIWiRp/45xB0u6O3d+yq2Z2RJU58jiTknnAj8knYYCqi+dlTQGOBXYHZgHTJM0NSLuKFR7ADgE+GzHtKsDxwGTSFde3ZynfaJGvGZmNsLqJIsVSElij0JZnUtntwdmR8QcAEnnAfsCLyWLiLgvj+s8vfVO4MqImJ/HXwlMBr5fI14zMxthde7gPnSY814HmFsYngfssBjTrjPMOMzMbDF1TRaS/p10BFEqIo6umLfKJqsZV61pJR0BHAEwYcKEmrM2M7N+9TqymL6Y854HrFcYXhd4sI9p394x7bWdlSLidOB0gEmTJtVNRGZm1qeuySIizlrMeU8DNpG0AfBb4CDgAzWnvQI4SdJqeXgP4POLGY+ZmQ1TnUtnhyUiFgFHkX74ZwEXRMRMSVMk7QMgaTtJ84ADgNMkzczTzgdOICWcacCUocZuMzMbvFpPnR2uiLgUuLSj7IuF/mmkU0xl055BuiHQzMyWsMaOLMzMbOlRmSwkbSrpKkm35+GtJR3bfGhmZtYWdY4svk1qXH4eICJuIzVWm5nZKFEnWawYETd1lC1qIhgzM2unOsniMUkbkW+Kyw/8e6jRqMzMrFXqXA11JOnGt80k/Ra4F/jrRqMyM7NW6ZksJC0DTIqI3SStBCwTEQsHE5qZmbVFz9NQEfEi6cY6IuJpJwozs9GpTpvFlZI+K2k9SasPdY1HZmZmrVGnzeKw/PfIQlkAG458OGZm1kZ13mexwSACMTOz9qpMFpI+XFYeEd8b+XDMzKyN6pyG2q7QvzywK3AL4GRhZjZK1DkN9cnisKTxwNmNRWRmZq0znKfOPgNsMtKBmJlZe9Vps/ghf3r/9TLAFsAPmgzKzMzapU6bxb8U+hcB90fEvIbiMTOzFqpzGupdEXFd7m6IiHmSvtx4ZGZm1hp1ksXuJWV7jnQgZmbWXl1PQ0n6BPA3wIaSbiuMWhm4oenAzMysPXq1WZwLXAZ8CTimUL4wIuY3GpWZmbVK12QREU8BTwHvB5D0atJNeeMkjYuIBwYTopmZLWmVbRaS9pZ0N+mlR9cB95GOOMzMbJSo08B9IvBm4Df5oYK74jYLM7NRpU6yeD4iHgeWkbRMRFwDbNtwXGZm1iJ1bsp7UtI44KfAf0l6hHRznpmZjRJ1jiz2JT0P6m+By4F7gL2bDMrMzNqlzlNnn5a0PrBJRJwlaUVgTPOhmZlZW9S5GuqjwIXAabloHeDiJoMyM7N2qXMa6khgJ2ABQETcDby6yaDMzKxd6iSL5yLij0MDksbyp0eWm5nZKFAnWVwn6f8DK0janfQuix82G5aZmbVJnWRxDPAoMAP4GHApcGyTQZmZWbv0eurshIh4ICJeBL6dOzMzG4V6HVm8dMWTpIuGM3NJkyXdJWm2pGNKxi8n6fw8/kZJE3P5REnPSro1d98azvLNzGxk9LrPQoX+DfudsaQxwKmklyfNA6ZJmhoRdxSqHQ48EREbSzoI+DJwYB53T0T4sSJmZi3Q68giuvTXtT0wOyLm5KupziPdDV60L3BW7r8Q2FWSMDOzVumVLLaRtEDSQmDr3L9A0kJJC2rMex1gbmF4Xi4rrRMRi0jvz1gjj9tA0q8kXSfpLbXWxszMGtHr5UeL+0iPsiOEziOUbnUeAiZExOOS/gK4WNKWEfGyJCXpCOAIgAkTJixmuGZm1k2dS2eHax6wXmF4XeDBbnXyzX7jgfkR8Vx+LDoRcTPp4YWbdi4gIk6PiEkRMWmttdZqYBXMzAyaTRbTgE0kbSBpWeAgYGpHnanAwbl/f+DqiAhJa+UGciRtCGwCzGkwVjMz66HO+yyGJSIWSToKuIL0lNozImKmpCnA9IiYCnwHOFvSbGA+KaEAvBWYImkR8ALw8YiY31SsZmbWW2PJAiAiLiXd8V0s+2Kh/w/AASXTXQQM694OMzMbeU2ehjIzs6WEk4WZmVVysjAzs0pOFmZmVsnJwszMKjlZmJlZJScLMzOr5GRhZmaVnCzMzKySk4WZmVVq9HEftnhO/fjVpeVHfmuXAUdiZqOdjyzMzKySk4WZmVVysjAzs0pOFmZmVsnJwszMKjlZmJlZJScLMzOr5GRhZmaVnCzMzKySk4WZmVVysjAzs0pOFmZmVsnJwszMKjlZmJlZJScLMzOr5PdZLGW+euC7S8s/c/4lA47EzJYmThaj3Lxjflpavu7JbxlwJGbWZj4NZWZmlZwszMyskk9DWV+OP/74YY0zs1c2Jwtr3FVXb1Ravusu95SWr33NraXlD79j267LmHjMj0rL7zt5rxGpbzbaOVmY1XH8+B7jniot3uqsrUrLZxw8o7R81mabl5Zvfues3rGZDYDbLMzMrJKPLMxewU79+NWl5Ud+a5cBR2JLu0aPLCRNlnSXpNmSjikZv5yk8/P4GyVNLIz7fC6/S9I7m4zTzMx6a+zIQtIY4FRgd2AeME3S1Ii4o1DtcOCJiNhY0kHAl4EDJW0BHARsCbwO+ImkTSPihabiNRsN+r3Dv9tNm9D9xs1uV8V1K+/3Agjo/yIIX9Cw+Jo8DbU9MDsi5gBIOg/YFygmi32B43P/hcApkpTLz4uI54B7Jc3O8/tFg/GamQHdkwv0SDDdLoIYoQsgljRFRDMzlvYHJkfER/Lwh4AdIuKoQp3bc515efgeYAdSAvllRJyTy78DXBYRF3Ys4wjgiDz4euCuLuGsCTzWR/hN119altHGmAaxjDbGNIhltDGmQSyjjTGN5DLWj4i1qiZu8shCJWWdmalbnTrTEhGnA6dXBiJNj4hJVfUGVX9pWUYbYxrEMtoY0yCW0caYBrGMNsY0qGUUNdnAPQ9YrzC8LvBgtzqSxgLjgfk1pzUzswFpMllMAzaRtIGkZUkN1lM76kwFDs79+wNXRzovNhU4KF8ttQGwCXBTg7GamVkPjZ2GiohFko4CrgDGAGdExExJU4DpETEV+A5wdm7Ank9KKOR6F5AawxcBRy7mlVCVp6oGXH9pWUYbYxrEMtoY0yCW0caYBrGMNsY0qGW8pLEGbjMzW3r4cR9mZlbJycLMzCo5WZiZWSU/SBCQtBmwDnBjRPy+UD45Ii7vUn/fPE2QLuudGhEj9ixpSdsDERHT8uNPJgN3RsSlI7WMxSXp1RHxSIPz35l05/7tEfHjppZTEcPQlXwPRsRPJH0A2BGYBZweEc+PwDJ2AGZFxAJJKwDHAG8iXeBxUkSU3wL8CifpaOB/ImJuH9NsBPwV6dL6RcDdwPeX1m3UjaTvRcSHB7nMUXVkIenQkrKjgf8FPgncLmnfwuiTSup/DjiPdOPgTaRLhAV8v+xhiYXpXiPpO5Iuy8NbSDq8S93jgG8A/yHpS8ApwDjgGElfqLWyFSStIulLks7OP4DFcd8sqb96R7cGcJOk1SSt3mUZkwv94/P63ybpXEmvKal/U6H/o6T1Xhk4rte2bdiZwF7ApySdDRwA3AhsB/xn3ZlIenWP0WcAz+T+r5PuN/pyLjuzn2CHPl+vECcAN0r6qaS/kdTzLuL8Xf0WsDxp+69AShq/kPT2ugvNn90lRtLakv5D0qmS1pB0vKQZki6Q9NqS+lM7uh8C7xka7rKM8ZJOlnSnpMdzNyuXrTqswCNi1HTAAyVlM4BxuX8iMB34VB7+VUn93wCvKilfFri7x7IvA94H/DoPjwVmdKk7g3S58YrAAmCVXL4CcFuXaSYB1wDnkL5AVwJPkZLZG0vqXwScDOxHuq/lImC5PO6WkvovAvd2dM/nv3O6xHRLof8/gROB9YG/Ay4uqf+rQv80YK3cv1KPbXULcCywUc3PwNrAf5AecrkG6dEyM4ALgNeW1L+t8P/6HTAmD6vH/2L1jm4N4D5gNWD1kvqzyrZZHr61pP6bunR/ATzUJabx+f99J/B47mblslW7TDMOmALMzJ+lR4FfAocM47t3Wdn/m7TDugfpMvpHgctJ916t3O17kftXBK7N/RMo+a7mcScDaxa+I3OA2cD9wNu6TLMK8CXgbOADHeO+WVJ/csd2/g5wG3Au8JqS+peTdk6PyfU+l9fhk8D/dvmMnwO8HXhb/vtQ7u+2Dlfk+a7d8dn/HHBlv/+/iFj6kkXe+GXdDOC5kvp3dAyPy//Mr3X5ot5JepZKZ/n6wF094pqW/xZ/EP9s/iV1ftUxrts0NwF7Au8H5gL75/JdgV+U1L+1Y/gLwA2kH7ayZPHZvF22KpTdW/G/uKXH8sq27a9JP6hrkO7FKd0mHeX3Av8CPJC3wd8Br+sRU79f1NtJOwKrAQvJP/akvdtZXZbRV2IFfgAcmvvPBCbl/k2HPjcd9V8AribtHHR2z3aJqe8fD9IR9yGkJyh8GvgH0g2yZ5FOj3XW7yuJdX7OgFcB+wDfBx4tqT+DP+3QrAbcXPw/dVmHGYX+a4DtCtt2epdp+t2RWpydogc6xpV9L5bJ87oS2DaXle6gFabp9VvUdVzPeQ5nojZ3pL2/bfM/q9hNJJ137qx/9dA/oFA2Fvge8EJJ/cmkPZPLSDe5nE76AZpNYQ+jZLprKfwQA28GrutS90ZgxaEPSqF8fNmHtcYHsOwIaVZx3rnsYNJe5P1dlrEu6Yfta6TTQ1Uf2HmkH5nPkPboVBj3Z3vlpL3vOeQfVfIPGymBd0uSxS/qW4BvAg/nH4Yj+txOZV/Uv8ux3A8cDVwFfJv0w3Vcl5j6Sqz5//pd4J78v38+L/M6YJuS+rcDm3SZ19wu5X3/eJCPggvDQzs8y5Dazzrr95XEyj6XhXErlJR9ipTgTyfttA0l2LWA67vM505gbO7/Zce4bker/e5I9b1TVOg/sU5MedzQ9++Uzs9uSd0fA39P4cgGeA1p5+AnvabtOs/hTNTmjnQIuHOXced2+Qes3aX+Tl3KlyH92L+X9JiSN5MPj3vE9ab8gXsq//0NsHWXust1KV+z+APUMe4XpMP5A0g/bPvl8rdRsgcFfAXYraR8Mj1Op+U6e5NORzxcUe+4jm7otNLawPf6+J+uCGzQZVzZl3dMXo8zS8b1/UUlvVPldbl/1fw/374i5r4Sa57evNXRAAADVUlEQVRmZWAb0p74n52+KNTbH3h9l3H7dSnv+8cD+PnQdyn/z68ojPuzBEOfSQzYtO5noDDNlnn9N6tZ/5N53XchnXL8N+CtwD8CZ3eZpq8dKfrfKZpCPvXdUb4xcGGNddqLkiO7jjqrkdq97gSeID0hY1Yu+7NTobW25XAmcje8jnTEsiXwBkraPRZz3tuQTjVcBmxGaih9Mn/Ad+wyzWak01TjOsr3rKpPaj95Qy7vdUTVbRldp+lzvc/rs/5ifVGHEV+txDqM+fa1XTt+POZ3/His1mWarUmn9p4Efjb0407akz+6pH7fSWwQHekc//mkNpIZwKWkVxuM7VK/rx0phrFT1PT3orCM3UZqGUvknzcaO+A9Jd2uwKsHsOxDS8o+SXr/x8Wk0z/7FsaV7a0f3U/94SxjEOs9kvX7mG8xsS72Mobzvxjp9W7Lth3k52Ok1nsQ34uR/oxEOFkMrAN+RNqbuyh3j+eyu4EPNbzskbgKrK/6w52m6fUeyfqDiGkQ23U4MbVx275S1nsQ34smluGb8gbnRWDziPgdpPsuSJdw7gBcT7pMb9gk3dZtFOncdKcxkW9AjIj78nXqF0pan/KXT/Vbf7jT9KXf9R7Gdmo8pmHoe7sOJ6Y2btt+tXS9G/9eNLEMJ4vBmTiUKLJHSOeA50ta7LuASR/Kd5Ias4pEaqjs9LCkbSPiVoCI+L2kd5NuECt7OXC/9Yc7Tb/6Xe9+6w8ipn4NZ7sOJ6Y2btt+tXG9B/G9GPFlOFkMzk8lXUK6QgbSlVTXS1qJ1IC4uC4hHXbe2jlC0rUl9T9MelzCSyJiEfBhSaeNQP3hTtOvfte73/qDiKlfw9muw4mpjdu2X21c70F8L0Z8GX6fxYBIEqlRe+dc9DjpjuEjl1xUZmb1jKpnQy1JkbLyPaQbrv6KdCXUiD140MysST4N1TBJm5KeWvp+0tHE+aQjuncs0cDMzPrg01ANk/Qi8FPg8IiYncvmRMSGSzYyM7P6fBqqee8lP6tI0rcl7crIXR5nZjYQPrIYkHzV036k01G7kJ7c+T+xhF7qY2bWDyeLJSC/LOgA4MCI2GVJx2NmVsXJwszMKrnNwszMKjlZmJlZJScLMzOr5GRhZmaVnCzMzKzS/wESN1gP1ChKTwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictors=list(X_train)\n",
    "feat_imp = pd.Series(random_model.feature_importances_, predictors).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Importance of Features')\n",
    "plt.ylabel('Feature Importance Score')\n",
    "print('Accuracy of the GBM on test set: {:.3f}'.format(random_model.score(X_test, y_test)))\n",
    "pred=random_model.predict(X_test)\n",
    "#print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0       33\n",
      "2.0       10\n",
      "3.0        4\n",
      "44.0       3\n",
      "6.0        3\n",
      "4.0        2\n",
      "21.0       2\n",
      "16.0       2\n",
      "17.0       2\n",
      "9.0        2\n",
      "67.0       1\n",
      "2124.0     1\n",
      "161.0      1\n",
      "32.0       1\n",
      "135.0      1\n",
      "3511.0     1\n",
      "77.0       1\n",
      "803.0      1\n",
      "43.0       1\n",
      "2872.0     1\n",
      "14.0       1\n",
      "1102.0     1\n",
      "26.0       1\n",
      "54.0       1\n",
      "4101.0     1\n",
      "31.0       1\n",
      "1497.0     1\n",
      "1175.0     1\n",
      "414.0      1\n",
      "137.0      1\n",
      "13.0       1\n",
      "127.0      1\n",
      "8.0        1\n",
      "36.0       1\n",
      "115.0      1\n",
      "968.0      1\n",
      "51.0       1\n",
      "631.0      1\n",
      "460.0      1\n",
      "504.0      1\n",
      "585.0      1\n",
      "808.0      1\n",
      "42.0       1\n",
      "1114.0     1\n",
      "41.0       1\n",
      "5.0        1\n",
      "Name: view_bucket, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
