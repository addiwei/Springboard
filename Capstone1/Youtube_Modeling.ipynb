{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 989 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      "search_word                  989 non-null object\n",
      "contentDetails.caption       989 non-null bool\n",
      "contentDetails.definition    989 non-null object\n",
      "catID                        989 non-null int64\n",
      "commentCount                 989 non-null float64\n",
      "dislikeCount                 989 non-null float64\n",
      "likeCount                    989 non-null float64\n",
      "tags_length                  989 non-null int64\n",
      "view_bucket                  989 non-null float64\n",
      "date                         989 non-null datetime64[ns, UTC]\n",
      "dtypes: bool(1), datetime64[ns, UTC](1), float64(4), int64(2), object(2)\n",
      "memory usage: 118.2+ KB\n",
      "None\n",
      "(989, 10)\n"
     ]
    }
   ],
   "source": [
    "#Split and scale the data, train hyper parameters, Model, Evaluate\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import cross_validation, metrics  \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "%store -r df\n",
    "\n",
    "print(df.info())\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(989, 4)\n",
      "(989, 4)\n"
     ]
    }
   ],
   "source": [
    "minmax_scale = preprocessing.MinMaxScaler().fit(df[['commentCount','dislikeCount','likeCount','tags_length']])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = pd.DataFrame(minmax_scale.transform(df[['commentCount','dislikeCount','likeCount','tags_length']]))\n",
    "print(X.shape)\n",
    "Y = df['view_bucket']\n",
    "\n",
    "n = pd.get_dummies(df[['search_word','contentDetails.definition','contentDetails.caption']])\n",
    "\n",
    "# X = pd.concat([X, n], axis=1)\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(989, 27)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = pd.concat([X, n], axis=1)\n",
    "X = pd.DataFrame(np.hstack([X,n]))\n",
    "X.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(989, 28)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the time series data and store as new date column\n",
    "ts = df['date']\n",
    "scaled_ts = (ts-ts.min())/(ts.max()-ts.min())\n",
    "\n",
    "X['date'] = pd.Series(scaled_ts)\n",
    "X['date'].fillna((X['date'].mean()), inplace=True)\n",
    "\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 890 entries, 304 to 684\n",
      "Data columns (total 28 columns):\n",
      "0       890 non-null object\n",
      "1       890 non-null object\n",
      "2       890 non-null object\n",
      "3       890 non-null object\n",
      "4       890 non-null object\n",
      "5       890 non-null object\n",
      "6       890 non-null object\n",
      "7       890 non-null object\n",
      "8       890 non-null object\n",
      "9       890 non-null object\n",
      "10      890 non-null object\n",
      "11      890 non-null object\n",
      "12      890 non-null object\n",
      "13      890 non-null object\n",
      "14      890 non-null object\n",
      "15      890 non-null object\n",
      "16      890 non-null object\n",
      "17      890 non-null object\n",
      "18      890 non-null object\n",
      "19      890 non-null object\n",
      "20      890 non-null object\n",
      "21      890 non-null object\n",
      "22      890 non-null object\n",
      "23      890 non-null object\n",
      "24      890 non-null object\n",
      "25      890 non-null object\n",
      "26      890 non-null object\n",
      "date    890 non-null float64\n",
      "dtypes: float64(1), object(27)\n",
      "memory usage: 201.6+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z002xczx\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=.9, random_state=0)\n",
    "\n",
    "X_train.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.722\n",
      "Model:                            OLS   Adj. R-squared:                  0.714\n",
      "Method:                 Least Squares   F-statistic:                     86.24\n",
      "Date:                Wed, 19 Dec 2018   Prob (F-statistic):          2.39e-219\n",
      "Time:                        13:35:28   Log-Likelihood:                -6135.3\n",
      "No. Observations:                 890   AIC:                         1.232e+04\n",
      "Df Residuals:                     863   BIC:                         1.245e+04\n",
      "Df Model:                          26                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "0          -1761.9512    300.543     -5.863      0.000   -2351.832   -1172.071\n",
      "1           4303.0008    225.969     19.042      0.000    3859.487    4746.514\n",
      "2           2375.3989    315.430      7.531      0.000    1756.298    2994.500\n",
      "3             64.1014     48.357      1.326      0.185     -30.810     159.013\n",
      "4              1.0185     25.094      0.041      0.968     -48.234      50.271\n",
      "5            -10.9123     35.661     -0.306      0.760     -80.905      59.080\n",
      "6             29.9146     36.922      0.810      0.418     -42.553     102.382\n",
      "7            -44.0537     36.132     -1.219      0.223    -114.971      26.864\n",
      "8              2.4880     36.797      0.068      0.946     -69.733      74.709\n",
      "9            208.9321     42.405      4.927      0.000     125.704     292.161\n",
      "10           -48.2274     35.716     -1.350      0.177    -118.327      21.873\n",
      "11             6.8512     36.466      0.188      0.851     -64.721      78.424\n",
      "12           -29.5451     37.124     -0.796      0.426    -102.409      43.319\n",
      "13           -19.7549     37.256     -0.530      0.596     -92.878      53.368\n",
      "14           -19.1885     36.416     -0.527      0.598     -90.662      52.285\n",
      "15            28.7398     36.315      0.791      0.429     -42.536     100.015\n",
      "16           -11.2118     36.571     -0.307      0.759     -82.990      60.566\n",
      "17           -25.0579     37.412     -0.670      0.503     -98.487      48.371\n",
      "18            38.4679     35.394      1.087      0.277     -31.001     107.937\n",
      "19           101.1463     46.599      2.171      0.030       9.686     192.607\n",
      "20            48.2301     36.439      1.324      0.186     -23.290     119.750\n",
      "21           -13.9187     35.590     -0.391      0.696     -83.772      55.935\n",
      "22            -6.8447     38.018     -0.180      0.857     -81.464      67.774\n",
      "23             8.4953     35.355      0.240      0.810     -60.897      77.888\n",
      "24           -30.7159     35.931     -0.855      0.393    -101.239      39.807\n",
      "25            70.9914     58.357      1.217      0.224     -43.546     185.529\n",
      "26           142.8433     63.944      2.234      0.026      17.339     268.348\n",
      "date         -84.3615     66.375     -1.271      0.204    -214.637      45.914\n",
      "==============================================================================\n",
      "Omnibus:                      420.946   Durbin-Watson:                   1.983\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           447512.704\n",
      "Skew:                          -0.528   Prob(JB):                         0.00\n",
      "Kurtosis:                     112.848   Cond. No.                     2.25e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 3.45e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = sm.OLS(list(y_train), X_train.astype(float)).fit()\n",
    "predictions = model.predict(X) \n",
    " \n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R squared: 0.7756\n",
      "Linear Regression RMSE: 322.1439\n",
      "Linear Regression MAE: 116.9394\n"
     ]
    }
   ],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "print('Linear Regression R squared: %.4f' % regressor.score(X_test, y_test))\n",
    "\n",
    "lin_mse = mean_squared_error(y_pred, y_test)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print('Linear Regression RMSE: %.4f' % lin_rmse)\n",
    "\n",
    "lin_mae = mean_absolute_error(y_pred, y_test)\n",
    "print('Linear Regression MAE: %.4f' % lin_mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try random forest with default hyperparameters\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "forest_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R squared: 0.3879\n",
      "Random Forest RMSE: 532.0794\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest R squared: %.4f' % forest_reg.score(X_test, y_test))\n",
    "y_pred = forest_reg.predict(X_test)\n",
    "forest_mse = mean_squared_error(y_pred, y_test)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print('Random Forest RMSE: %.4f' % forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and select optimal hyperparameters\n",
    "print(forest_reg.get_params())\n",
    "\n",
    "#Create a random grid for possible parameters to attempt and then use random search\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "#Print and evaluate best parameters from the search\n",
    "print(rf_random.best_params_)\n",
    "\n",
    "best_random = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 151.8758 degrees.\n",
      "Accuracy = 19.58%.\n"
     ]
    }
   ],
   "source": [
    "#Evaluate performance of the base model w/ searched hyperparameters\n",
    "\n",
    "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X_train, y_train)\n",
    "predictions = base_model.predict(X_test)\n",
    "errors = abs(predictions - y_test)\n",
    "mape = 100 * np.mean(errors / y_test)\n",
    "accuracy = 100 - mape\n",
    "print('Model Performance')\n",
    "print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 88.1599 degrees.\n",
      "Accuracy = -13.91%.\n"
     ]
    }
   ],
   "source": [
    "predictions = best_random.predict(X_test)\n",
    "errors = abs(predictions - y_test)\n",
    "mape = 100 * np.mean(errors / y_test)\n",
    "accuracy = 100 - mape\n",
    "print('Model Performance')\n",
    "print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "print('Accuracy = {:0.2f}%.'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try Grid Search to see if we can improve the hyperparameters further. \n",
    "# Setting grid around the previously identified optimal values\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [30, 40, 50, 60, 70],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 480 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   59.6s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 60,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 108.5852 degrees.\n",
      "Accuracy = -162.67%.\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "predictions = best_grid.predict(X_test)\n",
    "errors = abs(predictions - y_test)\n",
    "mape = 100 * np.mean(errors / y_test)\n",
    "accuracy = 100 - mape\n",
    "print('Model Performance')\n",
    "print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "print('Accuracy = {:0.2f}%.'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try Gradient Boosting\n",
    "model = ensemble.GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting R squared\": 0.0651\n",
      "Gradient Boosting RMSE: 657.5881\n"
     ]
    }
   ],
   "source": [
    "print('Gradient Boosting R squared\": %.4f' % model.score(X_test, y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "model_mse = mean_squared_error(y_pred, y_test)\n",
    "model_rmse = np.sqrt(model_mse)\n",
    "print('Gradient Boosting RMSE: %.4f' % model_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z002xczx\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:762: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.74355, std: 0.09953, params: {'learning_rate': 0.15, 'n_estimators': 100},\n",
       "  mean: 0.74335, std: 0.10029, params: {'learning_rate': 0.15, 'n_estimators': 200},\n",
       "  mean: 0.74366, std: 0.10062, params: {'learning_rate': 0.15, 'n_estimators': 300},\n",
       "  mean: 0.74369, std: 0.10066, params: {'learning_rate': 0.15, 'n_estimators': 400},\n",
       "  mean: 0.74364, std: 0.10067, params: {'learning_rate': 0.15, 'n_estimators': 500},\n",
       "  mean: 0.74133, std: 0.09621, params: {'learning_rate': 0.1, 'n_estimators': 100},\n",
       "  mean: 0.73960, std: 0.09697, params: {'learning_rate': 0.1, 'n_estimators': 200},\n",
       "  mean: 0.74055, std: 0.09789, params: {'learning_rate': 0.1, 'n_estimators': 300},\n",
       "  mean: 0.74062, std: 0.09781, params: {'learning_rate': 0.1, 'n_estimators': 400},\n",
       "  mean: 0.74074, std: 0.09788, params: {'learning_rate': 0.1, 'n_estimators': 500},\n",
       "  mean: 0.74759, std: 0.10437, params: {'learning_rate': 0.05, 'n_estimators': 100},\n",
       "  mean: 0.75242, std: 0.10806, params: {'learning_rate': 0.05, 'n_estimators': 200},\n",
       "  mean: 0.75319, std: 0.10891, params: {'learning_rate': 0.05, 'n_estimators': 300},\n",
       "  mean: 0.75202, std: 0.10934, params: {'learning_rate': 0.05, 'n_estimators': 400},\n",
       "  mean: 0.75220, std: 0.10923, params: {'learning_rate': 0.05, 'n_estimators': 500},\n",
       "  mean: 0.59619, std: 0.09762, params: {'learning_rate': 0.01, 'n_estimators': 100},\n",
       "  mean: 0.69770, std: 0.10027, params: {'learning_rate': 0.01, 'n_estimators': 200},\n",
       "  mean: 0.72509, std: 0.10205, params: {'learning_rate': 0.01, 'n_estimators': 300},\n",
       "  mean: 0.73252, std: 0.10356, params: {'learning_rate': 0.01, 'n_estimators': 400},\n",
       "  mean: 0.73794, std: 0.10522, params: {'learning_rate': 0.01, 'n_estimators': 500},\n",
       "  mean: 0.41893, std: 0.08352, params: {'learning_rate': 0.005, 'n_estimators': 100},\n",
       "  mean: 0.59109, std: 0.10219, params: {'learning_rate': 0.005, 'n_estimators': 200},\n",
       "  mean: 0.66646, std: 0.10488, params: {'learning_rate': 0.005, 'n_estimators': 300},\n",
       "  mean: 0.70214, std: 0.10291, params: {'learning_rate': 0.005, 'n_estimators': 400},\n",
       "  mean: 0.71819, std: 0.10174, params: {'learning_rate': 0.005, 'n_estimators': 500},\n",
       "  mean: 0.11033, std: 0.02876, params: {'learning_rate': 0.001, 'n_estimators': 100},\n",
       "  mean: 0.20475, std: 0.04705, params: {'learning_rate': 0.001, 'n_estimators': 200},\n",
       "  mean: 0.28446, std: 0.06228, params: {'learning_rate': 0.001, 'n_estimators': 300},\n",
       "  mean: 0.35354, std: 0.07406, params: {'learning_rate': 0.001, 'n_estimators': 400},\n",
       "  mean: 0.41052, std: 0.08246, params: {'learning_rate': 0.001, 'n_estimators': 500}],\n",
       " {'learning_rate': 0.05, 'n_estimators': 300},\n",
       " 0.7531939159875336)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic GBM Regressor performance was poor - try tuning learning rate and number of trees\n",
    "\n",
    "p_test3 = {'learning_rate':[0.15,0.1,0.05,0.01,0.005,0.001], 'n_estimators':[100,200,300,400,500]}\n",
    "\n",
    "tuning = GridSearchCV(estimator =GradientBoostingRegressor(max_depth=4, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10), \n",
    "            param_grid = p_test3,n_jobs=4,iid=False, cv=5)\n",
    "tuning.fit(X_train,y_train)\n",
    "tuning.grid_scores_, tuning.best_params_, tuning.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z002xczx\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:762: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.71886, std: 0.10170, params: {'max_depth': 2},\n",
       "  mean: 0.75168, std: 0.10093, params: {'max_depth': 3},\n",
       "  mean: 0.75319, std: 0.10891, params: {'max_depth': 4},\n",
       "  mean: 0.73977, std: 0.12580, params: {'max_depth': 5},\n",
       "  mean: 0.74374, std: 0.10745, params: {'max_depth': 6},\n",
       "  mean: 0.75210, std: 0.10823, params: {'max_depth': 7}],\n",
       " {'max_depth': 4},\n",
       " 0.7531939159875336)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tune max_depth utilizing learning_rate of .05 and n_estimators of 300\n",
    "\n",
    "p_test2 = {'max_depth':[2,3,4,5,6,7] }\n",
    "tuning = GridSearchCV(estimator =GradientBoostingRegressor(learning_rate=0.05,n_estimators=300, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10), \n",
    "            param_grid = p_test2,n_jobs=4,iid=False, cv=5)\n",
    "tuning.fit(X_train,y_train)\n",
    "tuning.grid_scores_, tuning.best_params_, tuning.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.05, loss='deviance', max_depth=4,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=300,\n",
       "              presort='auto', random_state=10, subsample=1, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = GradientBoostingClassifier(learning_rate=0.05, n_estimators=300,max_depth=4, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10)\n",
    "model1.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the GBM on test set: 0.374\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.64      0.91      0.75        33\n",
      "        2.0       0.38      0.30      0.33        10\n",
      "        3.0       0.25      0.50      0.33         4\n",
      "        4.0       0.00      0.00      0.00         2\n",
      "        5.0       0.00      0.00      0.00         1\n",
      "        6.0       1.00      0.33      0.50         3\n",
      "        7.0       0.00      0.00      0.00         0\n",
      "        8.0       0.00      0.00      0.00         1\n",
      "        9.0       1.00      0.50      0.67         2\n",
      "       10.0       0.00      0.00      0.00         0\n",
      "       11.0       0.00      0.00      0.00         0\n",
      "       13.0       0.00      0.00      0.00         1\n",
      "       14.0       0.00      0.00      0.00         1\n",
      "       15.0       0.00      0.00      0.00         0\n",
      "       16.0       0.00      0.00      0.00         2\n",
      "       17.0       0.00      0.00      0.00         2\n",
      "       18.0       0.00      0.00      0.00         0\n",
      "       21.0       0.00      0.00      0.00         2\n",
      "       22.0       0.00      0.00      0.00         0\n",
      "       26.0       0.00      0.00      0.00         1\n",
      "       27.0       0.00      0.00      0.00         0\n",
      "       29.0       0.00      0.00      0.00         0\n",
      "       31.0       0.00      0.00      0.00         1\n",
      "       32.0       0.00      0.00      0.00         1\n",
      "       36.0       0.00      0.00      0.00         1\n",
      "       41.0       0.00      0.00      0.00         1\n",
      "       42.0       0.00      0.00      0.00         1\n",
      "       43.0       0.00      0.00      0.00         1\n",
      "       44.0       0.00      0.00      0.00         3\n",
      "       51.0       0.00      0.00      0.00         1\n",
      "       54.0       0.00      0.00      0.00         1\n",
      "       55.0       0.00      0.00      0.00         0\n",
      "       67.0       0.00      0.00      0.00         1\n",
      "       77.0       0.00      0.00      0.00         1\n",
      "       84.0       0.00      0.00      0.00         0\n",
      "       91.0       0.00      0.00      0.00         0\n",
      "      107.0       0.00      0.00      0.00         0\n",
      "      115.0       0.00      0.00      0.00         1\n",
      "      127.0       0.00      0.00      0.00         1\n",
      "      135.0       0.00      0.00      0.00         1\n",
      "      137.0       0.00      0.00      0.00         1\n",
      "      161.0       0.00      0.00      0.00         1\n",
      "      301.0       0.00      0.00      0.00         0\n",
      "      322.0       0.00      0.00      0.00         0\n",
      "      346.0       0.00      0.00      0.00         0\n",
      "      414.0       0.00      0.00      0.00         1\n",
      "      460.0       0.00      0.00      0.00         1\n",
      "      492.0       0.00      0.00      0.00         0\n",
      "      504.0       0.00      0.00      0.00         1\n",
      "      585.0       0.00      0.00      0.00         1\n",
      "      631.0       0.00      0.00      0.00         1\n",
      "      634.0       0.00      0.00      0.00         0\n",
      "      803.0       0.00      0.00      0.00         1\n",
      "      808.0       0.00      0.00      0.00         1\n",
      "      943.0       0.00      0.00      0.00         0\n",
      "      968.0       0.00      0.00      0.00         1\n",
      "     1102.0       0.00      0.00      0.00         1\n",
      "     1114.0       0.00      0.00      0.00         1\n",
      "     1142.0       0.00      0.00      0.00         0\n",
      "     1175.0       0.00      0.00      0.00         1\n",
      "     1337.0       0.00      0.00      0.00         0\n",
      "     1460.0       0.00      0.00      0.00         0\n",
      "     1497.0       0.00      0.00      0.00         1\n",
      "     2124.0       0.00      0.00      0.00         1\n",
      "     2872.0       0.00      0.00      0.00         1\n",
      "     3511.0       0.00      0.00      0.00         1\n",
      "     4101.0       0.00      0.00      0.00         1\n",
      "     7786.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.31      0.37      0.33        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z002xczx\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\z002xczx\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEVCAYAAAARjMm4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xm0HFW5/vHvkwTCEAgQQGQIYZ6HqxEQUZRBg4igBAl4lUkRBXH8Sfhd0IiI4FK5eMEhChjDRUAciMgok4oIhDGEgESmhEEZQhLCGHjvH7UPFE11V/XJqT6dnOezVq1TtWtX9VvVffqtvWtoRQRmZmatDOrvAMzMrPs5WZiZWSknCzMzK+VkYWZmpZwszMyslJOFmZmVcrIw6yKSNpF0m6T5ko7u73jMejhZWJ+S9KCk3fo7DgBJ10r6VH/H0aavAddGxAoR8cPGmWmbXpD0bG5456K8oKRRkkLSkEVZjy3ZnCxsiaPM4vrZXheYXlLnqIgYlhtu6ERgzSzm+9sq8htstZF0sKTrJZ0q6RlJ90vaMZXPkvRvSQfl6v9C0k8kXZm6Ya6TtG5u/o6SbpY0N/3dMTfvWknflnQ98BwwGXg3cHo6+j491TstvfY8SbdIenduHRMkXSDpl+n1p0sanZu/jqTfSnpC0lM960zzDpU0Q9IcSZfn4y7YLx9O634mxb1ZKr8aeF8u5o3b3N+bpn33tKR7JX0sN2/P1L01L23/hNyif05/n+lpqaR9cU5u+Te0Pgr29/qShks6U9Jjkh6RdKKkwan+hun9nCvpSUnnt7Nt1gUiwoOHPhuAB4Hd0vjBwELgEGAwcCLwMHAGMBR4PzAfGJbq/yJNvyfNPw34a5q3CjAH+AQwBDggTY9I869N694izV8qlX2qIb7/BEakOl8BHgeWSfMmAC8AH0zxfgf4e5o3GLgDOBVYHlgG2CnN2weYCWyW1nsc8Lcm+2djYAGwe4rxa2nZpXPb8akW+7dwfoppVtrXQ4C3AU8CW6T57wW2IjtA3Br4F7BPmjcKCGBIbn0TgHNy02+o02R//x74aYpldeAm4DOp/q+A/0qv/9q+87D4DG5ZWN0eiIizI+IV4HxgHeCEiHgxIq4AXgI2zNX/Y0T8OSJeJPtyeaekdYA9gfsiYnJELIyIXwH3AHvllv1FRExP818uCiYizomIp1Kd75MlpU1yVf4aEZekeCcD26Ty7YA1gf8XEQsi4oWI+Gua9xngOxExIyIWAicB2zZpXeyftvHKFOP3gGWBHQvqNvPD1Cp5RtKtqexDwINpXy+MiFuB3wBj03ZfGxHTIuLViLiT7Mt75zZes8hr+5ssme8BfDHtn3+TJdZxqe7LZF1sazbsO1tMOFlY3f6VG38eICIay4blpmf1jETEs8DTZF/SawIPNaz7IWCtomWbkfSV1F00V9IzwHBg1VyVx3PjzwHLpK6XdYCH0hdjo3WB03q+wFPMaoitxxu2IyJeTXEX1W3m6IhYKQ1vy8WwfS6JPAN8HFgjbff2kq5JXWhzgSMatrs38vt7XbLWxWO51/8pWQsDshaUgJtSF9yhi/ja1mG++sG6zTo9I5KGkR2xPpqGxiP1kcBluenGRyi/YTqdnzgG2BWYHhGvSppD9iVWZhYwUtKQgoQxC/h2RPxvhfU8StYd1BOTyLb5kQrLlsV3XUTs3mT+ucDpwB4R8YKk/+b1ZFH06OkFwHK56TUK6uSXmwW8CKxalFAj4nHg0wCSdgL+JOnPETGzxTZZF3HLwrrNByXtJGlp4FvAjRExC7gE2FjSgZKGSNof2By4uMW6/gWsn5tegewcyhPAEElfB1asGNdNwGPAyZKWl7SMpHeleT8BjpW0BUA60btfk/VcAOwpaVdJS5GdN3kR+FvFOJq5mGz/fELSUml4R8/Jc7Jtfzoliu2AA3PLPgG8yhv31e3AeySNlDQcOLbVi0fEY8AVwPclrShpkKQNJO0MIGk/SWun6nPIEs0ri7jN1kFOFtZtzgW+QdaV83ayrhQi4imyfvmvAE+RdWt8KCKebLGu04Cx6QqlHwKXA5cC/yDrCnqBCl1X6fVfITs/siHZid3ZZOcfiIjfAacA50maB9xF1n9ftJ57yU6y/w/ZCei9gL0i4qUqcbSIbz7ZBQPjyFovj6eYhqYqnwNOkDQf+DpZ0upZ9jng28D1qQtph4i4kuwc053ALbROyj0+CSwN3E2WEC4E3prmvQO4UdKzwBTgCxHxQO+32DpNEf7xI+sOkn4BzI6I4/o7FjN7I7cszMyslJOFmZmVcjeUmZmVcsvCzMxKOVmYmVmpJeamvFVXXTVGjRrV32GYmS1WbrnllicjYrWyektMshg1ahRTp07t7zDMzBYrkhofo1PI3VBmZlbKycLMzEo5WZiZWSknCzMzK+VkYWZmpZwszMyslJOFmZmVcrIwM7NSS8xNeXmjxv+xsPzBk/fscCRmZksGtyzMzKyUk4WZmZVysjAzs1JOFmZmVsrJwszMSjlZmJlZqSXy0tm2TRjepHxuZ+MwM+tSblmYmVkpJwszMyvlZGFmZqVqTRaSxki6V9JMSeML5g+VdH6af6OkUQ3zR0p6VtJX64zTzMxaqy1ZSBoMnAHsAWwOHCBp84ZqhwFzImJD4FTglIb5pwKX1hWjmZlVU2fLYjtgZkTcHxEvAecBezfU2RuYlMYvBHaVJABJ+wD3A9NrjNHMzCqoM1msBczKTc9OZYV1ImIhMBcYIWl54BjgmzXGZ2ZmFdWZLFRQFhXrfBM4NSKebfkC0uGSpkqa+sQTT/QyTDMzK1PnTXmzgXVy02sDjzapM1vSEGA48DSwPTBW0neBlYBXJb0QEafnF46IicBEgNGjRzcmIjMz6yN1JoubgY0krQc8AowDDmyoMwU4CLgBGAtcHREBvLungqQJwLONicLMzDqntmQREQslHQVcDgwGzoqI6ZJOAKZGxBTgTGCypJlkLYpxdcVjZma9V+uzoSLiEuCShrKv58ZfAPYrWceEWoIzM7PKfAe3mZmV8lNne2GrSVsVlk87aFqHIzEz6wy3LMzMrJSThZmZlXKyMDOzUk4WZmZWysnCzMxKOVmYmVkpJwszMyvlZGFmZqWcLMzMrJSThZmZlXKyMDOzUk4WZmZWysnCzMxKVU4WkpavMxAzM+tepclC0o6S7gZmpOltJP2o9sjMzKxrVGlZnAp8AHgKICLuAN5TZ1BmZtZdKnVDRcSshqJXaojFzMy6VJVfypslaUcgJC0NHE3qkjIzs4GhSsviCOBIYC1gNrBtmjYzswGiZctC0mDgExHx8Q7FY2ZmXahlyyIiXgH27lAsZmbWpaqcs7he0unA+cCCnsKIuLW2qMzMrKtUSRY7pr8n5MoC2KXvwzEzs25Umiwi4n2dCMTMzLpXlTu4h0v6gaSpafi+pOGdCM7MzLpDlUtnzwLmAx9Lwzzg7DqDMjOz7lLlnMUGEbFvbvqbkm6vKyAzM+s+VVoWz0vaqWdC0ruA5+sLyczMuk2VlsVngUm58xRzgINri8jMzLpOlauhbge2kbRimp5Xe1RmZtZVqlwNdZKklSJiXkTMk7SypBM7EZyZmXWHKucs9oiIZ3omImIO8MH6QjIzs25TJVkMljS0Z0LSssDQFvXNzGwJU+UE9znAVZLOJnvMx6HApFqjMjOzrlLlBPd3Jd0J7JaKvhURl9cblpmZdZMqLQsi4jJJN5P99vaT9YZkZmbdpuk5C0kXS9oyjb8VuIusC2qypC92KD4zM+sCrU5wrxcRd6XxQ4ArI2IvYHuypFFK0hhJ90qaKWl8wfyhks5P82+UNCqVbyfp9jTcIekjbW2VmZn1qVbJ4uXc+K7AJQARMR94tWzF6SdZzwD2ADYHDpC0eUO1w4A5EbEhcCpwSiq/CxgdEdsCY4CfSqrUZWZmZn2vVbKYJenz6aj+bcBl8Nqls0tVWPd2wMyIuD8iXgLO480/0bo3r19ZdSGwqyRFxHMRsTCVL0N2FZaZmfWTVsniMGALsudA7Z+7MW8Hqj2ifC1gVm56diorrJOSw1xgBICk7SVNB6YBR+SSh5mZdVjTrp2I+DdwREH5NcA1FdatotVWrRMRNwJbSNqM7EGGl0bEC29YWDocOBxg5MiRFUIyM7PeqHIHd2/NBtbJTa8NPNqsTjonMRx4Ol8hImYAC4AtG18gIiZGxOiIGL3aaqv1YehmZpZXZ7K4GdhI0nqSlgbGAVMa6kwBDkrjY4GrIyLSMkMAJK0LbAI8WGOsZmbWQm1XGEXEQklHAZcDg4GzImK6pBOAqRExBTiT7L6NmWQtinFp8Z2A8ZJeJrvy6nMRsdjeDDhj080Kyze7Z0aHIzEz653SZCFpY+DHwFsiYktJWwMfjojSx5RHxCWkS25zZV/Pjb8A7Few3GRgcnn4ZmbWCVW6oX4GHEu67yIi7uT1FoCZmQ0AVZLFchFxU0OZL2M1MxtAqiSLJyVtQLqkVdJY4LFaozIzs65S5QT3kcBEYFNJjwAPAP9Za1RmZtZVqvyexf3AbpKWBwalZ0OZmdkAUtoNJekkSStFxIKImC9pZUmlV0KZmdmSo8o5iz1yz4UiIuYAH6wvJDMz6zZVksVgSUN7JtJTZ4e2qG9mZkuYKie4zwGuknQ22RVRh/L6Y8XNzGwAqHKC+7uSppH9AJKAb0XE5bVHZmZmXaPSs6Ei4lLg0ppjMTOzLlXlaqiPSrpP0lxJ8yTNlzSvE8GZmVl3qNKy+C6wV/pdCTMzG4CqXA31LycKM7OBrUrLYqqk84HfAy/2FEbEb2uLyszMukqVZLEi8Bzw/lxZAE4WZmYDRJVLZw/pRCBmZta9qvxS3jLAYcAWwDI95RFxaI1xmZlZF6lygnsysAbwAeA6YG3AT541MxtAqiSLDSPieGBBREwC9gS2qjcsMzPrJlWSxcvp7zOStgSGA6Nqi8jMzLpOlauhJkpaGTgOmAIMA46vNSozM+sqVZLFVek3LP4MrA8gab1aozIzs65SpRvqNwVlF/Z1IGZm1r2atiwkbUp2uexwSR/NzVqR3CW0Zma25GvVDbUJ8CFgJWCvXPl84NN1BmVmZt2labKIiIskXQwcExEndTAmMzPrMi3PWUTEK8DuHYrFzMy6VJWrof4m6XTgfGBBT2FE3FpbVGZm1lWqJIsd098TcmUB7NL34ZiZWTeq8tTZ93UiEDMz615VfoN7uKQfSJqahu9LGt6J4MzMrDtUuSnvLLLLZT+WhnnA2XUGZWZm3aXKOYsNImLf3PQ3Jd1eV0BmZtZ9qrQsnpe0U8+EpHcBz9cXkpmZdZsqLYvPApPSeQoBTwMH1RqVmZl1lSpXQ90ObCNpxTQ9r/aozMysq1S5GmqEpB8C1wLXSDpN0ojaIzMzs65R5ZzFecATwL7A2DR+fp1BmZlZd6mSLFaJiG9FxANpOJHsSbSlJI2RdK+kmZLGF8wfKun8NP9GSaNS+e6SbpE0Lf313eJmZv2oSrK4RtI4SYPS8DHgj2ULSRoMnAHsAWwOHCBp84ZqhwFzImJD4FTglFT+JLBXRGxFdjJ9crXNMTOzOlS5GuozwJeBc9L0IGCBpC8DERErNlluO2BmRNwPIOk8YG/g7lydvYEJafxC4HRJiojbcnWmA8tIGhoRL1aId7F3xhFXF5Yf+RM3sMysf1S5GmqFXq57LWBWbno2sH2zOhGxUNJcYARZy6LHvsBtAyVRmJl1oyotCyRtDYzK14+I35YtVlAW7dSRtAVZ19T7m8R1OHA4wMiRI0vCMTOz3ipNFpLOArYm6w56NRUHUJYsZgPr5KbXBh5tUme2pCHAcLKb/pC0NvA74JMR8c+iF4iIicBEgNGjRzcmIjMz6yNVWhY7RETjiekqbgY2krQe8AgwDjiwoc4UshPYN5Bdlnt1RISklchOoh8bEdf34rXNzKwPVbka6oaCq5hKRcRC4CjgcmAGcEFETJd0gqQPp2pnAiMkzSQ7id5zee1RwIbA8ZJuT8Pq7cZgZmZ9o0rLYhJZwngceJHsPENExNZlC0bEJcAlDWVfz42/AOxXsNyJwIkVYjMzsw6okizOAj4BTOP1cxZmZjaAVEkWD0fElNojMTOzrlUlWdwj6VzgD2TdUEClS2fNzGwJUSVZLEuWJPL3OlS5dNbMzJYQVe7gPqQTgZiZWfdqmiwk/Q9vvuP6NRFxdC0RmZlZ12nVspjasSjMzKyrNU0WETGpk4GYmVn3qnIHt5mZDXBOFmZmVsrJwszMSpUmC0kbS7pK0l1pemtJx9UfmpmZdYsqLYufAccCLwNExJ1kjxs3M7MBokqyWC4ibmooW1hHMGZm1p2qJIsnJW1AukFP0ljgsVqjMjOzrlLl2VBHkv106aaSHgEeAD5ea1RmZtZVWiYLSYOA0RGxm6TlgUERMb8zoZmZWbdo2Q0VEa+S/cQpEbHAicLMbGCqcs7iSklflbSOpFV6htojMzOzrlHlnMWh6e+RubIA1u/7cMzMrBtV+T2L9ToRiJmZda/SZCHpk0XlEfHLvg/HzMy6UZVuqHfkxpcBdgVuBZwszMwGiCrdUJ/PT0saDkyuLSIzM+s6vXnq7HPARn0diJmZda8q5yz+wOu/xT0I2Bz4dZ1BmZlZd6lyzuJ7ufGFwEMRMbumeMzMrAtV6Yb6YERcl4brI2K2pFNqj8zMzLpGlWSxe0HZHn0diJmZda+m3VCSPgt8Dlhf0p25WSsA19cdmJmZdY9W5yzOBS4FvgOMz5XPj4ina43KzMy6StNkERFzgbnAAQCSVie7KW+YpGER8XBnQjQzs/5Wes5C0l6S7iP70aPrgAfJWhxmZjZAVDnBfSKwA/CP9FDBXfE5CzOzAaVKsng5Ip4CBkkaFBHXANvWHJeZmXWRKjflPSNpGPAX4H8l/Zvs5jwzMxsgqrQs9iZ7HtQXgcuAfwJ71RmUmZl1lypPnV0gaV1go4iYJGk5YHD9oZmZWbeocjXUp4ELgZ+morWA39cZlJmZdZcq3VBHAu8C5gFExH3A6lVWLmmMpHslzZQ0vmD+UEnnp/k3ShqVykdIukbSs5JOr7oxZmZWjyrJ4sWIeKlnQtIQXn9keVOSBgNnkD1HanPgAEmbN1Q7DJgTERsCpwI9Dyh8ATge+GqF+MzMrGZVksV1kv4/sKyk3cl+y+IPFZbbDpgZEfenZHMe2cnyvL2BSWn8QmBXSYqIBRHxV7KkYWZm/axKshgPPAFMAz4DXAIcV2G5tYBZuenZqaywTkQsJHu8yIgK6zYzsw5q9dTZkRHxcES8CvwsDe1QQVlj91WVOs1fQDocOBxg5MiR1SMzM7O2tGpZvHbFk6Tf9GLds4F1ctNrA482q5POhQwHKj/RNiImRsToiBi92mqr9SJEMzOrolWyyB/1r9+Ldd8MbCRpPUlLA+OAKQ11pgAHpfGxwNURUbllYWZmndHqprxoMl5JRCyUdBRwOdlNfGdFxHRJJwBTI2IKcCYwWdJMshbFuJ7lJT0IrAgsLWkf4P0RcXe7cZiZ2aJrlSy2kTSPrIWxbBonTUdErFi28oi4hOyEeL7s67nxF4D9miw7qmz9ZmbWGa1+/MiP9DAzM6DapbNmZjbAOVmYmVkpJwszMyvlZGFmZqWcLMzMrJSThZmZlXKyMDOzUk4WZmZWysnCzMxKOVmYmVkpJwszMyvlZGFmZqWcLMzMrJSThZmZlXKyMDOzUk4WZmZWysnCzMxKOVmYmVkpJwszMyvlZGFmZqWcLMzMrJSThZmZlXKyMDOzUk4WZmZWysnCzMxKOVmYmVmpIf0dgC267+//ocLyr5x/cYcjMbMllVsWZmZWysnCzMxKuRtqAJo9/i+F5Wuf/O4OR2JmiwsnCys1YcKEtsqvunqDwvJdd/lnH0VkZp3mZGH9bo1rbi8sf/x923Y4EjNrxsnCFjujxv+xsPzBk/fscCRmA4dPcJuZWSm3LGyJ13ZLZMLwJuVz+ygis8WPk4XZItpq0laF5dMOmlZYPmPTzQrLN7tnRmH5GUdcXVh+5E92KSxv9yZNXx1nVThZmFlb+uLquGZXxrV7sYPPX3WOk4WZDRjukuw9Jwszsz7Sbpfk4qTWZCFpDHAaMBj4eUSc3DB/KPBL4O3AU8D+EfFgmncscBjwCnB0RFxeZ6xmZp3W7vmr/lRbspA0GDgD2B2YDdwsaUpE3J2rdhgwJyI2lDQOOAXYX9LmwDhgC2BN4E+SNo6IV+qK18ys29V9sUMrdd5nsR0wMyLuj4iXgPOAvRvq7A1MSuMXArtKUio/LyJejIgHgJlpfWZm1g8UEfWsWBoLjImIT6XpTwDbR8RRuTp3pTqz0/Q/ge2BCcDfI+KcVH4mcGlEXNjwGocDh6fJTYB7C0JZFXiyjdBd3/Vdv5763RSL679u3YhYrWzhOs9ZqKCsMTM1q1NlWSJiIjCxZRDS1IgY3aqO67u+69dfv5ticf321dkNNRtYJze9NvBoszqShgDDgacrLmtmZh1SZ7K4GdhI0nqSliY7YT2loc4U4KA0Pha4OrJ+sSnAOElDJa0HbATcVGOsZmbWQm3dUBGxUNJRwOVkl86eFRHTJZ0ATI2IKcCZwGRJM8laFOPSstMlXQDcDSwEjlyEK6FadlO5vuu7fsfqd1Msrt+m2k5wm5nZksOPKDczs1JOFmZmVsrJwszMSg34BwlK2pTsjvG1yO7leBSYEhGFD2dJ9dcCboyIZ3PlYyLisj6IZzsgIuLm9NiTMcA9EXFJxeV/GRGfXNQ4cuvbAPgI2aXMC4H7gF9FRFc8dlPS6hHx7/6Oo69J2h6YERHzJC0LjAfeRnbRx0mN+1/S0cDvImLWIrzmiIh4alHi7la5KzIfjYg/SToQ2BGYAUyMiJf7NcA2SdqJ7KkWd0XEFZ14zQHTspB0SEHZMWSPIRHZpbk3p/FfSRpfUP9o4CLg88BdkvKPLzmpxWtvLOmqdMc6kraWdFxBvW8APwR+LOk7wOnAMGC8pP8qqD+lYfgD8NGe6eZ74w3rGNFi3tHAT4BlgHcAy5IljRskvbfK+nPrurSd+k3WsUrDMAK4SdLKklYpqL+GpB9LOkPSCEkTJE2TdIGktxbUH5MbHy7pTEl3SjpX0lsWNf42nQU8l8ZPI7sH6ZRUdnZB/W8BN0r6i6TPSWp5R66kkyWtmsZHS7o/Lf+QpJ37bCtqkt6fkyXdI+mpNMxIZSsVLHI2sCfwBUmTgf2AG8k+1z8vWP+Kkr4jaXJKLPl5P6phk5C0eot5N+XGP0323bAC8I2i76paRMSAGICHC8r+ASxVUL40cF9B+TRgWBofBUwFvpCmb2vx2teRHQXcliu7q8n6BwPLAfOAFVP5ssCdBfVvBc4B3gvsnP4+lsZ3Lqh/MrBqGh8N3E/23K2HmtSfBgxO48sB16bxkUXbS3bkWzS8HXisoP5o4Jq0DesAVwJzyZL2fxTUfxV4oGF4Of29v6D+ZWSJfTxwJ3BMiv3zwEVF+zM3/nPgRGBd4EvA75vs/+OADSp+Boen9+AesqcsP0V2ZHsysFJD3RlFcaXp2wvWfRvZwd/7yS5JfyJt/0HACkXvbW78GuAdaXxjskvbi+JfEfgOMBk4sGHejwrqDwNOAKan9/UJ4O/AwU3WvwbwY7IHkI4ge+zPNOAC4K0NdS9P7+caDcsfA1xZsO47098hwL9yn2tR/L/1m/S+7EN239dvgKFF70cqG9PwPp+ZPnPnAm8pqL9KwzACeBBYGVil6P3Njd8MrJbGl8+/lxU/h5e2U/+15XqzULcO6c0pGqYBLxbUv4fsuSiN5esC9xaU390wPSz9Q/6g6B84/+YWvOGF//BF4y3qDyL7IrsS2DaVvelLM1e/rS+ItN96/kFWBm7JzStKdq8AV6d1Nw7PF9S/CdgDOACYBYxN5bsCNxTU/2ra31vlyh5osb35/flww7yi/Xlrs/lN6j8AfA94OG3Ll4A1W8RT+QsO+DVwSBo/Gxide69ubhV7ml4K+DDwK+CJJp/9IWn8780+Jw3l7X6BXgQcTPYEhi8Dx5PdYDuJrCutsX7l5E7B/2erecBdZAeBKwPzSV/IZK3mGQX1G9///wKuJ/tSL9rWdg802j3wuSPFPoKG/1X64MCtytD2At08kB0xbJvepPwwiqyvsrH+GLIj60vJbliZmD6wM8kdKeTqX036Us6VDSH7TY5XWsR1KbBBzweK7G71N2V3smbxcml8UK58eNEHNDd/bbIvl9MpaEHl6rX1BQF8If3TTkzL9nx5rQb8uaD+XcBGTV57VkFZqy/zwpZablt/QNYMb5Uc78iNn1hhe2eTfal9hazVpdy8wpZdbvzdwI+Ax8mS4+EF9St/waX3/BfAP9Pn4uUU03XANq32ZcG8ZQvKPg9cAexCdgT/38B7gG8Ck5usp90v0DsapnsOmgaRnYdr5/PQ+NpXAF8jd9QOvIUswfypYN1fSvvvIeBo4CrgZ2QHRN8oqD+D3P9gKjuIrJX0UMlnocqBRrsHPg+m+B9If9dI5cOarL+tA7cqQ9sLdPNA1vTbqcm8c5uUDwJ2APYl+xLfgdRELai7NrmjwoZ572oR1/rAn8j6mx8B/kpxi2Zok+VXzX+oWrzOnhQcseXm9+YLYou0Xzat8PpjgU2azNunoOwGsm6T/dI/8T6pfGeadIXklt2LrEvj8RZ1TiB1GzaUbwhcWFD+jYahp6m/BvDLgvpFX5CDyQ5Czi6Y19YXXJq/ArAN2RHhm7ozcvU2Lnt/CpZ5L3A+WRfWNOASsqc4v6lrNtVv9wv0bz3/j+n9ujw3r+jov3JyJzvKPoXsIGYO2RMgZqSyN3XjpGXWJLX8gJXS53W7JnW/C+xWUD6G4i7qtg40UnnlA58W7+FywHoF5W0duFV6rd4s5KHtN3S99Hd5Uv9x0RvcoViafUEM6aP1b0rWjTSsobyopbYNWdfMpWm504Bn0pfPjmXrJzuXs2Wz9bcbTy/iP6/NfZP/gnu64Qtu5X74LLS7b9r9At2arHvuGbIDpI1T+Wpkv37ZWL/d5L4psFvV+Ptw/+xRULetA42GZUsPfHoRe1sHbpXW2ekP6EAcKD4CvaXTcZTEeEgfrONost80icTXAAACbElEQVQU+T1Zs3nvVvug3XjaXT9ZS6q2+n25P/ti//fXe9WJ7W2s39fx9/dngTce+NT6Wejt+jv24RyIQzoy2Zes3/mjueFgYHp/x9cQa9NzHW2so1dXi1WNp931112/L/dnX+z//nqvOrG9jfX7Ov6B9Fno7foH/E15NdsE+BBZ/+heufL5wKc7HYykO5vNIus7X1SDI92oGBEPpnsxLpS0LgU/aNWLeNpaf931242/A/u/He3um9q3t836bcffpsX6s1DH+p0sahQRFwEXSXpnRNzQ3/GQfUg+QHZCME9kJyMX1eOSto2I2wEi4llJHyK7wWyrPoin3fXXXb/d+Ove/+1od1uh/u1tp35v4m/H4v5Z6PP1O1l0xm2SjiS7smiZnsKIOLTDcVxM1rS+vXGGpGv7YP2fJHskyGsiYiHwSUk/7YN42l1/3fXbjb/u/d+OdrcV6t/edur3Jv52LO6fhT5fv3/PogMk/ZrsCpgDya74+DjZjUBf6NfAzMwqcrLoAEm3RcR/SLozIraWtBTZNee79HdsZmZVDJgHCfaznidaPiNpS7K7c0f1XzhmZu3xOYvOmChpZbKHzk0hu6Hs+P4NycysOndD1UjSl4uK09+IiB90Mh4zs95yy6JeK6S/m5A9N7/nNyb2Av7cLxGZmfWCWxYdIOkKYN+ImJ+mVwB+HRFjWi9pZtYdfIK7M0YCL+WmX8InuM1sMeJuqM6YTPbzn78j+53vj5D9AIyZ2WLB3VAdIultZD+QA9kPB93Wn/GYmbXDycLMzEr5nIWZmZVysjAzs1JOFmZmVsrJwszMSjlZmJlZqf8Dggmt1+HpntwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictors=list(X_train)\n",
    "feat_imp = pd.Series(model1.feature_importances_, predictors).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Importance of Features')\n",
    "plt.ylabel('Feature Importance Score')\n",
    "print('Accuracy of the GBM on test set: {:.3f}'.format(model1.score(X_test, y_test)))\n",
    "pred=model1.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try tree related parameters\n",
    "\n",
    "p_test4 = {'min_samples_split':[2,4,6,8,10,20,40,60,100], 'min_samples_leaf':[1,3,5,7,9]}\n",
    "\n",
    "tuning = GridSearchCV(estimator =GradientBoostingRegressor(learning_rate=0.05, n_estimators=300,max_depth=4, subsample=1,max_features='sqrt', random_state=10), \n",
    "            param_grid = p_test4,n_jobs=4,iid=False, cv=5)\n",
    "tuning.fit(X_train,y_train)\n",
    "tuning.grid_scores_, tuning.best_params_, tuning.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
