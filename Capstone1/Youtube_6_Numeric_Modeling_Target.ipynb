{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 989 entries, 0 to 999\n",
      "Data columns (total 18 columns):\n",
      "search_word                  989 non-null object\n",
      "contentDetails.caption       989 non-null bool\n",
      "contentDetails.definition    989 non-null object\n",
      "catID                        989 non-null int64\n",
      "description                  975 non-null object\n",
      "localized.description        974 non-null object\n",
      "localized.title              989 non-null object\n",
      "tags                         930 non-null object\n",
      "title                        989 non-null object\n",
      "commentCount                 989 non-null float64\n",
      "dislikeCount                 989 non-null float64\n",
      "likeCount                    989 non-null float64\n",
      "view_bucket                  989 non-null float64\n",
      "date                         989 non-null datetime64[ns, UTC]\n",
      "Aging                        989 non-null datetime64[ns]\n",
      "Age                          989 non-null timedelta64[ns]\n",
      "age_int                      989 non-null int64\n",
      "target                       989 non-null bool\n",
      "dtypes: bool(2), datetime64[ns, UTC](1), datetime64[ns](1), float64(4), int64(2), object(7), timedelta64[ns](1)\n",
      "memory usage: 133.3+ KB\n",
      "None\n",
      "(989, 18)\n"
     ]
    }
   ],
   "source": [
    "#Split and scale the data, train hyper parameters, Model, Evaluate\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import cross_validation, metrics  \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "%store -r df\n",
    "\n",
    "print(df.info())\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(989, 3)\n",
      "(989, 3)\n"
     ]
    }
   ],
   "source": [
    "minmax_scale = preprocessing.MinMaxScaler().fit(df[['commentCount','dislikeCount','likeCount']])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = pd.DataFrame(minmax_scale.transform(df[['commentCount','dislikeCount','likeCount']]))\n",
    "print(X.shape)\n",
    "Y = df['target']\n",
    "\n",
    "n = pd.get_dummies(df[['search_word','contentDetails.definition','contentDetails.caption']])\n",
    "\n",
    "# X = pd.concat([X, n], axis=1)\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(989, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the dummy columns as variables\n",
    "X = pd.DataFrame(np.hstack([X,n]))\n",
    "X.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(989, 27)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the time series data and store as new date column\n",
    "ts = df['Age']\n",
    "scaled_ts = (ts-ts.min())/(ts.max()-ts.min())\n",
    "\n",
    "X['Age'] = pd.Series(scaled_ts)\n",
    "X['Age'].fillna((X['Age'].mean()), inplace=True)\n",
    "\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000190146</td>\n",
       "      <td>0.000486296</td>\n",
       "      <td>0.000165565</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0186383</td>\n",
       "      <td>4.25509e-05</td>\n",
       "      <td>1.24485e-05</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0186383</td>\n",
       "      <td>0.000316092</td>\n",
       "      <td>0.000129998</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0186383</td>\n",
       "      <td>0.00124005</td>\n",
       "      <td>0.000681999</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000104011</td>\n",
       "      <td>0.00013981</td>\n",
       "      <td>0.000127686</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0            1            2      3  4  5  6  7  8  9    ...     \\\n",
       "0  0.000190146  0.000486296  0.000165565  False  1  0  0  0  0  0    ...      \n",
       "1    0.0186383  4.25509e-05  1.24485e-05  False  1  0  0  0  0  0    ...      \n",
       "2    0.0186383  0.000316092  0.000129998  False  1  0  0  0  0  0    ...      \n",
       "3    0.0186383   0.00124005  0.000681999  False  1  0  0  0  0  0    ...      \n",
       "4  0.000104011   0.00013981  0.000127686  False  1  0  0  0  0  0    ...      \n",
       "\n",
       "  17 18 19 20 21 22 23 24 25       Age  \n",
       "0  0  0  0  0  0  0  0  1  0  0.083642  \n",
       "1  0  0  0  0  0  0  0  1  0  0.095886  \n",
       "2  0  0  0  0  0  0  0  1  0  0.484491  \n",
       "3  0  0  0  0  0  0  0  1  0  0.012972  \n",
       "4  0  0  0  0  0  0  0  1  0  0.002331  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 890 entries, 304 to 684\n",
      "Data columns (total 27 columns):\n",
      "0      890 non-null object\n",
      "1      890 non-null object\n",
      "2      890 non-null object\n",
      "3      890 non-null object\n",
      "4      890 non-null object\n",
      "5      890 non-null object\n",
      "6      890 non-null object\n",
      "7      890 non-null object\n",
      "8      890 non-null object\n",
      "9      890 non-null object\n",
      "10     890 non-null object\n",
      "11     890 non-null object\n",
      "12     890 non-null object\n",
      "13     890 non-null object\n",
      "14     890 non-null object\n",
      "15     890 non-null object\n",
      "16     890 non-null object\n",
      "17     890 non-null object\n",
      "18     890 non-null object\n",
      "19     890 non-null object\n",
      "20     890 non-null object\n",
      "21     890 non-null object\n",
      "22     890 non-null object\n",
      "23     890 non-null object\n",
      "24     890 non-null object\n",
      "25     890 non-null object\n",
      "Age    890 non-null float64\n",
      "dtypes: float64(1), object(26)\n",
      "memory usage: 194.7+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z002xczx\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=.9, random_state=0)\n",
    "\n",
    "X_train.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.274\n",
      "Model:                            OLS   Adj. R-squared:                  0.253\n",
      "Method:                 Least Squares   F-statistic:                     13.06\n",
      "Date:                Tue, 15 Jan 2019   Prob (F-statistic):           4.70e-45\n",
      "Time:                        11:08:22   Log-Likelihood:                -478.80\n",
      "No. Observations:                 890   AIC:                             1010.\n",
      "Df Residuals:                     864   BIC:                             1134.\n",
      "Df Model:                          25                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "0             -0.3411      0.522     -0.654      0.513      -1.365       0.683\n",
      "1              2.7924      0.392      7.121      0.000       2.023       3.562\n",
      "2             -1.5923      0.548     -2.908      0.004      -2.667      -0.518\n",
      "3             -0.0015      0.042     -0.035      0.972      -0.085       0.082\n",
      "4              0.3885      0.064      6.094      0.000       0.263       0.514\n",
      "5              0.0465      0.063      0.738      0.461      -0.077       0.170\n",
      "6             -0.1765      0.061     -2.874      0.004      -0.297      -0.056\n",
      "7             -0.1274      0.063     -2.031      0.043      -0.251      -0.004\n",
      "8              0.4784      0.072      6.662      0.000       0.337       0.619\n",
      "9             -0.0967      0.060     -1.601      0.110      -0.215       0.022\n",
      "10            -0.1493      0.061     -2.430      0.015      -0.270      -0.029\n",
      "11             0.0546      0.063      0.868      0.385      -0.069       0.178\n",
      "12            -0.1851      0.063     -2.942      0.003      -0.309      -0.062\n",
      "13            -0.2045      0.061     -3.339      0.001      -0.325      -0.084\n",
      "14            -0.0384      0.062     -0.622      0.534      -0.159       0.083\n",
      "15            -0.1080      0.062     -1.747      0.081      -0.229       0.013\n",
      "16            -0.3103      0.062     -5.043      0.000      -0.431      -0.190\n",
      "17             0.3094      0.061      5.105      0.000       0.190       0.428\n",
      "18             0.1184      0.081      1.463      0.144      -0.040       0.277\n",
      "19             0.2466      0.063      3.936      0.000       0.124       0.370\n",
      "20             0.0475      0.060      0.790      0.429      -0.070       0.166\n",
      "21            -0.1563      0.064     -2.438      0.015      -0.282      -0.030\n",
      "22             0.1754      0.062      2.843      0.005       0.054       0.297\n",
      "23             0.2942      0.065      4.519      0.000       0.166       0.422\n",
      "24             0.3214      0.018     17.540      0.000       0.285       0.357\n",
      "25             0.2857      0.055      5.185      0.000       0.178       0.394\n",
      "Age            0.0507      0.115      0.440      0.660      -0.175       0.277\n",
      "==============================================================================\n",
      "Omnibus:                       49.203   Durbin-Watson:                   2.036\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               31.731\n",
      "Skew:                           0.335   Prob(JB):                     1.29e-07\n",
      "Kurtosis:                       2.362   Cond. No.                     2.25e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.79e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = sm.OLS(list(y_train), X_train.astype(float)).fit()\n",
    "predictions = model.predict(X) \n",
    " \n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R squared: 0.2405\n",
      "Linear Regression RMSE: 0.4320\n",
      "Linear Regression MAE: 0.3552\n"
     ]
    }
   ],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "print('Linear Regression R squared: %.4f' % regressor.score(X_test, y_test))\n",
    "\n",
    "lin_mse = mean_squared_error(y_pred, y_test)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print('Linear Regression RMSE: %.4f' % lin_rmse)\n",
    "\n",
    "lin_mae = mean_absolute_error(y_pred, y_test)\n",
    "print('Linear Regression MAE: %.4f' % lin_mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors=list(X_train)\n",
    "# feat_imp = pd.Series(regressor.feature_importances_, predictors).sort_values(ascending=False)\n",
    "# feat_imp.plot(kind='bar', title='Importance of Features')\n",
    "# plt.ylabel('Feature Importance Score')\n",
    "# print('Accuracy of the linear regression model on test set: {:.3f}'.format(regressor.score(X_test, y_test)))\n",
    "# pred=regressor.predict(X_test)\n",
    "# print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try random forest with default hyperparameters\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "forest_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R squared: 0.5601\n",
      "Random Forest RMSE: 0.3288\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest R squared: %.4f' % forest_reg.score(X_test, y_test))\n",
    "y_pred = forest_reg.predict(X_test)\n",
    "forest_mse = mean_squared_error(y_pred, y_test)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print('Random Forest RMSE: %.4f' % forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and select optimal hyperparameters\n",
    "print(forest_reg.get_params())\n",
    "\n",
    "#Create a random grid for possible parameters to attempt and then use random search\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, scoring = 'neg_mean_squared_error', n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 50, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "#Print and evaluate best parameters from the search\n",
    "print(rf_random.best_params_)\n",
    "\n",
    "best_random = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate performance of the base model w/ searched hyperparameters\n",
    "\n",
    "random_model = RandomForestRegressor(n_estimators = 200, min_samples_split=2, min_samples_leaf=1, \n",
    "                                   max_features = 'sqrt', max_depth = 50, bootstrap = True, random_state = 42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=50,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R squared: 0.5718\n",
      "Random Forest RMSE: 0.3243\n"
     ]
    }
   ],
   "source": [
    "#Evaluate performance of random forest with random searched hyperparameters\n",
    "print('Random Forest R squared: %.4f' % random_model.score(X_test, y_test))\n",
    "y_pred = random_model.predict(X_test)\n",
    "forest_mse = mean_squared_error(y_pred, y_test)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print('Random Forest RMSE: %.4f' % forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try Grid Search to see if we can improve the hyperparameters further. \n",
    "# Setting grid around the previously identified optimal values\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [30, 40, 50, 60, 70],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, scoring = 'neg_mean_squared_error',\n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 480 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 40,\n",
       " 'max_features': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 300}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R squared: -0.1077\n",
      "Random Forest RMSE: 0.3282\n"
     ]
    }
   ],
   "source": [
    "#Evaluate performance of random forest with grid search hyperparameters\n",
    "print('Random Forest R squared: %.4f' % grid_search.score(X_test, y_test))\n",
    "y_pred = grid_search.predict(X_test)\n",
    "forest_mse = mean_squared_error(y_pred, y_test)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print('Random Forest RMSE: %.4f' % forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try Gradient Boosting\n",
    "model = ensemble.GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting R squared\": 0.5907\n",
      "Gradient Boosting RMSE: 0.3171\n"
     ]
    }
   ],
   "source": [
    "print('Gradient Boosting R squared\": %.4f' % model.score(X_test, y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "model_mse = mean_squared_error(y_pred, y_test)\n",
    "model_rmse = np.sqrt(model_mse)\n",
    "print('Gradient Boosting RMSE: %.4f' % model_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.9, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'ls', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'presort': 'auto', 'random_state': None, 'subsample': 1.0, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [100, 311, 522, 733, 944, 1155, 1366, 1577, 1788, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 10, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   38.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [100, 311, 522, 733, 944, 1155, 1366, 1577, 1788, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic GBM Regressor performance was poor - try tuning learning rate and number of trees\n",
    "gbm = GradientBoostingRegressor()\n",
    "\n",
    "gbm_random = RandomizedSearchCV(estimator = gbm, param_distributions = random_grid, scoring = 'neg_mean_squared_error', n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "gbm_random.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "#Print and evaluate best parameters from the search\n",
    "print(gbm_random.best_params_)\n",
    "\n",
    "best_random = gbm_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate performance of the base model w/ searched hyperparameters\n",
    "\n",
    "random_model = GradientBoostingRegressor(n_estimators = 100, min_samples_split=10, min_samples_leaf=1, \n",
    "                                   max_features = 'sqrt', max_depth = 4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=4,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=10,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "             presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM - random searched R squared: 0.5924\n",
      "GBM - random searched RMSE: 0.3165\n"
     ]
    }
   ],
   "source": [
    "#Evaluate performance of GBM with random searched hyperparameters\n",
    "print('GBM - random searched R squared: %.4f' % random_model.score(X_test, y_test))\n",
    "y_pred = random_model.predict(X_test)\n",
    "forest_mse = mean_squared_error(y_pred, y_test)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print('GBM - random searched RMSE: %.4f' % forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the GBM on test set: 0.592\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictors=list(X_train)\n",
    "feat_imp = pd.Series(random_model.feature_importances_, predictors).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Importance of Features')\n",
    "plt.ylabel('Feature Importance Score')\n",
    "print('Accuracy of the GBM on test set: {:.3f}'.format(random_model.score(X_test, y_test)))\n",
    "pred=random_model.predict(X_test)\n",
    "#print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    56\n",
      "True     43\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
